{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import plotter as pltr\n",
    "pltr.set_backend(pltr.MatplotlibBackend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as dutils\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [0.5]\n",
    "stds = [0.5]\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "white = pltr.Color(red=255, green=255, blue=255)\n",
    "big_white_font = pltr.Font(color=white, size=14)\n",
    "\n",
    "Metric = namedtuple('Metric', ['name', 'train', 'val'])\n",
    "\n",
    "def tensor2img(tensor):\n",
    "    \"\"\"\n",
    "    Tensor of size 1xHxW: Supposed to be an image with a single channel\n",
    "    Returns an ndarray of shape HxW of type int with values between 0 and 255.\n",
    "    \"\"\"\n",
    "    img = copy(tensor.cpu().detach().numpy())\n",
    "    img = img.squeeze()  # Get rid fo the single channel dim\n",
    "    img = img * stds + means  # De-normalize\n",
    "    img = np.clip(img, 0, 1)\n",
    "    img = 255 * img  # Re-scale to 0-255\n",
    "    img = img.astype(np.int)\n",
    "    return img\n",
    "\n",
    "def show_imgs(imgs, titles):\n",
    "    \"\"\"\n",
    "    imgs: list of ndarrays of shape HxW\n",
    "    titles: list of strings\n",
    "    \"\"\"\n",
    "    frame = pltr.Frame()\n",
    "    frame.layout(1, len(imgs))  # Show all the images in a single row\n",
    "    for img, title in zip(imgs, titles):\n",
    "        chart = frame.create_chart()\n",
    "        chart.title = title\n",
    "        chart.title_font = big_white_font\n",
    "        chart.show_axes = False\n",
    "        imgplot = pltr.GrayscaleImage(img)\n",
    "        chart.add(imgplot)\n",
    "    frame.show()\n",
    "    \n",
    "def show_classification(img: np.ndarray, label: str, probs: np.ndarray):\n",
    "    \"\"\"\n",
    "    img: ndarray of shape HxW. Supposed to be a grayscale image\n",
    "    probs: ndarray of shape K. Supposed to be the probability of each class\n",
    "    \"\"\"\n",
    "    frame = pltr.Frame()\n",
    "    frame.layout(1, 2)\n",
    "    \n",
    "    # Image chart\n",
    "    chart = frame.create_chart()\n",
    "    chart.title = label\n",
    "    chart.title_font = big_white_font\n",
    "    chart.show_axes = False\n",
    "    imgplot = pltr.GrayscaleImage(img)\n",
    "    chart.add(imgplot)\n",
    "    \n",
    "    # Probs plot\n",
    "    chart = frame.create_chart()\n",
    "    chart.title = 'Class Probabilities'\n",
    "    chart.title_font = big_white_font\n",
    "    chart.x_axis.limits = (0, 1)\n",
    "    chart.x_axis.font = pltr.Font(color=white)\n",
    "    chart.y_axis.font = pltr.Font(color=white)\n",
    "    cats = [str(v) for v in range(len(probs))]\n",
    "    probsplot = pltr.HorizontalBar(categories=cats, values=probs)\n",
    "    chart.add(probsplot)\n",
    "    \n",
    "    frame.show()\n",
    "    \n",
    "def plot_learning_curves(*metrics):\n",
    "    frame = pltr.Frame(height_px=1100, width_px=2000)\n",
    "    frame.layout(len(metrics), 1)\n",
    "    train_color = pltr.Color(red=7, green=87, blue=124)\n",
    "    val_color = pltr.Color(red=124, green=7, blue=87)\n",
    "    for metric in metrics:\n",
    "        chart = frame.create_chart()\n",
    "        chart.title = metric.name.upper()\n",
    "        chart.title_font = big_white_font\n",
    "        chart.x_axis = pltr.Axis(label='Epochs', font=pltr.Font(color=white))\n",
    "        chart.y_axis.font = pltr.Font(color=white)\n",
    "        chart.legend_location = pltr.LegendLocation.BEST\n",
    "        \n",
    "        epochs = [str(i) for i in range(len(metric.train))]\n",
    "        \n",
    "        train_line = pltr.Line(categories=epochs, values=metric.train, legend='Train', color=train_color)\n",
    "        chart.add(train_line)\n",
    "        \n",
    "        val_line = pltr.Line(categories=epochs, values=metric.val, legend='Val', color=val_color)\n",
    "        chart.add(val_line)\n",
    "    frame.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View without any transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x10C0A6550>, tensor(5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata = datasets.MNIST('/data/pytorch/mnist/', download=True, train=True)\n",
    "traindata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titles = []\n",
    "imgs = []\n",
    "for i in range(5):\n",
    "    pil_img, label = traindata[i]\n",
    "    imgs.append(np.array(pil_img))\n",
    "    titles.append(str(label.item()))\n",
    "show_imgs(imgs, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataset.Subset'>\n",
      "<class 'tuple'>\n",
      "torch.Size([1, 28, 28])\n",
      "tensor(6)\n",
      "torch.Size([1, 28, 28])\n",
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "xforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(means, stds)\n",
    "])\n",
    "traindata = datasets.MNIST('/data/pytorch/mnist', download=True, train=True, transform=xforms)\n",
    "train_size = int(0.8*(len(traindata)))\n",
    "val_size = len(traindata) - train_size\n",
    "trainset, valset = dutils.random_split(traindata, (train_size, val_size))\n",
    "print(type(trainset))\n",
    "print(type(trainset[0]))\n",
    "\n",
    "train_image, train_label = trainset[0]\n",
    "print(train_image.size())\n",
    "print(train_label)\n",
    "val_image, val_label = valset[0]\n",
    "print(val_image.size())\n",
    "print(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs = [tensor2img(train_image), tensor2img(val_image)]\n",
    "titles = [str(train_label.item()), str(val_label.item())]\n",
    "show_imgs(imgs, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = dutils.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = dutils.DataLoader(valset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "\n",
    "#### Layer 1\n",
    "28x28x1 → CONV(5, ch=10) → 24x24x10 → MAXPOOL(2) → 12x12x10 → RELU → 12x12x10\n",
    "####   \n",
    "#### Layer 2\n",
    "12x12x10 → CONV(5, ch=20) → 8x8x20 → DROPOUT → 8x8x20 → MAXPOOL(2) → 4x4x20 → RELU → 4x4x20\n",
    "####  \n",
    "#### Layer 3\n",
    "4x4x20 → FLATTEN → 320 → LINEAR(320, 50) → 50 → RELU → 50 → DROPOUT → 50\n",
    "####  \n",
    "#### Layer 4\n",
    "50 → LINEAR(50, 10) → 10 → LOG-SOFTMAX → 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(F.dropout(self.conv2(x), training=self.training), 2))\n",
    "        x = F.dropout(F.relu(self.fc1(x.view(-1, 320))), training=self.training)\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for single batch: 0:00:00.046743\n",
      "Loss: 147.879\tAccuracy: 0.078\n"
     ]
    }
   ],
   "source": [
    "# Train single batch\n",
    "model = Net()\n",
    "model = model.to(DEVICE)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "start = datetime.now()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.to(DEVICE)\n",
    "labels = labels.to(DEVICE)\n",
    "with torch.enable_grad():\n",
    "    optimizer.zero_grad()\n",
    "    log_probs = model.forward(images)\n",
    "    loss = loss_fn(log_probs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    batch_loss = loss.item() * images.size(0)\n",
    "    preds = torch.argmax(log_probs, dim=1)\n",
    "    batch_acc = torch.sum(preds == labels.data)\n",
    "end = datetime.now()\n",
    "elapsed = end - start\n",
    "print(f'Time taken for single batch: {elapsed}')\n",
    "print(f'Loss: {batch_loss:.3f}\\tAccuracy: {batch_acc.double()/images.size(0):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets see how the model performs on the val image\n",
    "# First create a batch of 1\n",
    "image = val_image.view(1, 1, 28, 28).to(DEVICE)\n",
    "log_probs = model.forward(image)\n",
    "print(log_probs.size())  # Should be 1x10\n",
    "probs = torch.exp(log_probs)\n",
    "\n",
    "img = tensor2img(val_image)\n",
    "title = str(val_label.item())\n",
    "probs = probs.cpu().detach().numpy().flatten()\n",
    "show_classification(img, title, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "Train - Loss: 1.296\tAccuracy: 0.565\n",
      "Val - Loss: 0.620\tAccuracy: 0.799\n",
      "Time: 0:00:21.031580\n",
      "\n",
      "Epoch 2/3\n",
      "Train - Loss: 0.482\tAccuracy: 0.848\n",
      "Val - Loss: 0.405\tAccuracy: 0.871\n",
      "Time: 0:00:21.683469\n",
      "\n",
      "Epoch 3/3\n",
      "Train - Loss: 0.341\tAccuracy: 0.894\n",
      "Val - Loss: 0.301\tAccuracy: 0.907\n",
      "Time: 0:00:22.042168\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = Net()\n",
    "model = model.to(DEVICE)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 3\n",
    "losses = Metric(name='loss', train=[], val=[])\n",
    "accuracies = Metric(name='Accuracy', train=[], val=[])\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "    start = datetime.now()\n",
    "    train_epoch_loss = 0.0\n",
    "    train_epoch_acc = 0\n",
    "    for batch, (images, labels) in enumerate(trainloader):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        with torch.enable_grad():\n",
    "            optimizer.zero_grad()\n",
    "            log_probs = model.forward(images)\n",
    "            loss = loss_fn(log_probs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             print(f'Batch {batch} Grads after step: {model.fc2.weight.grad[0, :5]}')\n",
    "            batch_loss = loss * images.size(0)\n",
    "            preds = torch.argmax(log_probs, dim=1)\n",
    "            batch_acc = torch.sum(preds == labels)\n",
    "            train_epoch_loss += batch_loss\n",
    "            train_epoch_acc += batch_acc\n",
    "    train_epoch_loss = train_epoch_loss / len(trainset)\n",
    "    train_epoch_acc = train_epoch_acc.double() / len(trainset)\n",
    "    print(f'Train - Loss: {train_epoch_loss:.3f}\\tAccuracy: {train_epoch_acc:.3f}')\n",
    "    losses.train.append(train_epoch_loss)\n",
    "    accuracies.train.append(train_epoch_acc)\n",
    "    \n",
    "    # Calculate the validation metrics\n",
    "    val_epoch_loss = 0.0\n",
    "    val_epoch_acc = 0\n",
    "    for images, labels in valloader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            log_probs = model.forward(images)\n",
    "            loss = loss_fn(log_probs, labels)\n",
    "            \n",
    "            batch_loss = loss * images.size(0)\n",
    "            preds = torch.argmax(log_probs, dim=1)\n",
    "            batch_acc = torch.sum(preds == labels)\n",
    "            val_epoch_loss += batch_loss\n",
    "            val_epoch_acc += batch_acc\n",
    "    val_epoch_loss = val_epoch_loss / len(valset)\n",
    "    val_epoch_acc = val_epoch_acc.double() / len(valset)\n",
    "    losses.val.append(val_epoch_loss)\n",
    "    accuracies.val.append(val_epoch_acc)\n",
    "    print(f'Val - Loss: {val_epoch_loss:.3f}\\tAccuracy: {val_epoch_acc:.3f}')\n",
    "    \n",
    "    end = datetime.now()\n",
    "    print(f'Time: {end - start}')\n",
    "    \n",
    "print('Training Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(losses, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how the model performs on the val image\n",
    "# First create a batch of 1\n",
    "model.eval()\n",
    "image = val_image.view(1, 1, 28, 28).to(DEVICE)\n",
    "log_probs = model.forward(image)\n",
    "print(log_probs.size())  # Should be 1x10\n",
    "probs = torch.exp(log_probs)\n",
    "\n",
    "img = tensor2img(val_image)\n",
    "title = str(val_label.item())\n",
    "probs = probs.cpu().detach().numpy().flatten()\n",
    "show_classification(img, title, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate test metrics\n",
    "testset = datasets.MNIST('/data/pytorch/mnist', download=True, train=False, transform=xforms)\n",
    "test_image, test_label = testset[0]\n",
    "print(test_image.size())\n",
    "print(test_label)\n",
    "\n",
    "testloader = dutils.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_acc = 0\n",
    "for images, labels in testloader:\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        log_probs = model.forward(images)\n",
    "        loss = loss_fn(log_probs, labels)\n",
    "\n",
    "        batch_loss = loss * images.size(0)\n",
    "        preds = torch.argmax(log_probs, dim=1)\n",
    "        batch_acc = torch.sum(preds == labels)\n",
    "        test_loss += batch_loss\n",
    "        test_acc += batch_acc\n",
    "test_loss = test_loss / len(valset)\n",
    "test_acc = test_acc.double() / len(valset)\n",
    "print(f'Test - Loss: {test_loss:.3f}\\tAccuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
