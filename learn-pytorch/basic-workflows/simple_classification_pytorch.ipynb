{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as skdata\n",
    "import torch as t\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from dataclasses import dataclass\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(t.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = t.nn.Linear(20, 8)\n",
    "        self.fc2 = t.nn.Linear(8, 1)\n",
    "    \n",
    "    def forward(self, batch_x):\n",
    "        x = t.nn.functional.relu(self.fc1(batch_x))\n",
    "        batch_y_hat = t.sigmoid(self.fc2(x))\n",
    "        return t.squeeze(batch_y_hat, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Hyperparams:\n",
    "    n_epochs: int\n",
    "    batch_size: int\n",
    "    lr: float\n",
    "    true_cutoff: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_datasets(n_samples):\n",
    "    X, y = skdata.make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=20,\n",
    "        n_informative=10,\n",
    "        n_redundant=7,\n",
    "        n_repeated=3,\n",
    "        n_classes=2,\n",
    "        flip_y=0.05,  # larger values make the task hard\n",
    "        class_sep=0.5,  # larger values makes the task easy\n",
    "        random_state=10\n",
    "    )\n",
    "    \n",
    "    train_size = int(n_samples * 0.7)\n",
    "    val_size = int(n_samples * 0.2)\n",
    "\n",
    "    train_X = X[:train_size]\n",
    "    train_y = y[:train_size]\n",
    "    trainset = t.utils.data.TensorDataset(\n",
    "        t.from_numpy(train_X).to(t.float32),\n",
    "        t.from_numpy(train_y).to(t.float32)\n",
    "    )\n",
    "\n",
    "    val_X = X[train_size : train_size + val_size]\n",
    "    val_y = y[train_size : train_size + val_size]\n",
    "    valset = t.utils.data.TensorDataset(\n",
    "        t.from_numpy(val_X).to(t.float32),\n",
    "        t.from_numpy(val_y).to(t.float32)\n",
    "    )\n",
    "\n",
    "    test_X = X[train_size + val_size :]\n",
    "    test_y = y[train_size + val_size :]\n",
    "    testset = t.utils.data.TensorDataset(\n",
    "        t.from_numpy(test_X).to(t.float32),\n",
    "        t.from_numpy(test_y).to(t.float32)\n",
    "    )\n",
    "    \n",
    "    return trainset, valset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Hyperparams(n_epochs=10, batch_size=32, lr=0.005, true_cutoff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset, testset = gen_datasets(n_samples=100_000)\n",
    "traindl = t.utils.data.DataLoader(trainset, batch_size=hparams.batch_size)\n",
    "valdl = t.utils.data.DataLoader(valset, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogReg()\n",
    "optim = t.optim.Adam(model.parameters(), lr=hparams.lr)\n",
    "loss_fn = t.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train accuracy=0.818, Val accuracy=0.849, Train loss=0.410, Val loss=0.362\n",
      "Epoch 2: Train accuracy=0.855, Val accuracy=0.869, Train loss=0.353, Val loss=0.337\n",
      "Epoch 3: Train accuracy=0.868, Val accuracy=0.873, Train loss=0.333, Val loss=0.327\n",
      "Epoch 4: Train accuracy=0.874, Val accuracy=0.874, Train loss=0.325, Val loss=0.320\n",
      "Epoch 5: Train accuracy=0.878, Val accuracy=0.876, Train loss=0.319, Val loss=0.315\n",
      "Epoch 6: Train accuracy=0.881, Val accuracy=0.878, Train loss=0.315, Val loss=0.313\n",
      "Epoch 7: Train accuracy=0.883, Val accuracy=0.880, Train loss=0.312, Val loss=0.314\n",
      "Epoch 8: Train accuracy=0.886, Val accuracy=0.883, Train loss=0.310, Val loss=0.311\n",
      "Epoch 9: Train accuracy=0.888, Val accuracy=0.884, Train loss=0.308, Val loss=0.309\n",
      "Epoch 10: Train accuracy=0.893, Val accuracy=0.888, Train loss=0.302, Val loss=0.309\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, hparams.n_epochs + 1):\n",
    "    y_hat = t.Tensor([])\n",
    "    y = t.Tensor([])\n",
    "    batch_losses = []\n",
    "    model.train()\n",
    "    with t.enable_grad():\n",
    "        for batch_X, batch_y in traindl:\n",
    "            optim.zero_grad()\n",
    "            batch_y_hat = model.forward(batch_X)\n",
    "            loss = loss_fn(batch_y_hat, batch_y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            batch_losses.append(loss.detach().item())\n",
    "            y_hat = t.cat((y_hat, batch_y_hat.detach()))\n",
    "            y = t.cat((y, batch_y.detach()))\n",
    "    y_pred = y_hat > hparams.true_cutoff\n",
    "    train_acc = accuracy_score(y, y_pred)\n",
    "    train_loss = sum(batch_losses)/len(batch_losses)\n",
    "    \n",
    "    y_hat = t.Tensor([])\n",
    "    y = t.Tensor([])\n",
    "    batch_losses = []\n",
    "    model.eval()\n",
    "    with t.no_grad():\n",
    "        for batch_X, batch_y in valdl:\n",
    "            batch_y_hat = model(batch_X)\n",
    "            loss = loss_fn(batch_y_hat, batch_y)\n",
    "            batch_losses.append(loss.detach().item())\n",
    "            y_hat = t.cat((y_hat, batch_y_hat))\n",
    "            y = t.cat((y, batch_y))\n",
    "    y_pred = y_hat > hparams.true_cutoff\n",
    "    val_acc = accuracy_score(y, y_pred)\n",
    "    val_loss = sum(batch_losses)/len(batch_losses)\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Train accuracy={train_acc:.3f}, Val accuracy={val_acc:.3f}, Train loss={train_loss:.3f}, Val loss={val_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy=0.874 Test loss=0.328\n"
     ]
    }
   ],
   "source": [
    "testdl = t.utils.data.DataLoader(testset, batch_size=5000)\n",
    "y_hat = t.Tensor([])\n",
    "y = t.Tensor([])\n",
    "batch_losses = []\n",
    "model.eval()\n",
    "with t.no_grad():\n",
    "    for batch_X, batch_y in testdl:\n",
    "        batch_y_hat = model(batch_X)\n",
    "        loss = loss_fn(batch_y_hat, batch_y)\n",
    "        batch_losses.append(loss.detach().item())\n",
    "        y_hat = t.cat((y_hat, batch_y_hat))\n",
    "        y = t.cat((y, batch_y))\n",
    "y_pred = y_hat > hparams.true_cutoff\n",
    "test_acc = accuracy_score(y, y_pred)\n",
    "test_loss = sum(batch_losses)/len(batch_losses)\n",
    "print(f\"Test accuracy={test_acc:.3f} Test loss={test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1933,  0.3040,  0.2339, -0.4712, -2.0335, -0.1256,  0.3059, -1.0716,\n",
       "           0.2664, -0.2187,  1.4983,  1.5031, -0.9345, -1.2143,  0.6086,  0.4412,\n",
       "          -0.7629, -0.4040,  0.9199,  0.5362],\n",
       "         [-0.8095,  0.3273, -0.1031,  0.5970, -0.2447,  0.0505,  0.8312, -0.9991,\n",
       "           0.1177,  0.4486,  1.0565,  0.9103,  0.8362, -1.6116,  0.7527, -0.4848,\n",
       "          -0.3421,  1.4960, -0.3365, -0.0799],\n",
       "         [-1.6605,  1.0875,  0.1025, -0.5268,  0.7196,  0.2690, -0.7103, -0.1966,\n",
       "           1.3231,  0.8041, -0.1564,  0.0364, -0.2973,  0.6151, -0.5530,  0.1251,\n",
       "          -0.2612,  0.7585,  0.1787, -0.4786],\n",
       "         [-1.2165, -0.3393, -0.0241, -0.8325, -0.3739, -0.3921,  0.9219,  0.4433,\n",
       "          -0.0687,  0.4376, -0.6073, -0.8516,  0.7861,  0.6547,  0.6940,  0.0043,\n",
       "          -0.2669,  0.3149, -0.7328, -0.4379],\n",
       "         [ 0.7825, -0.3184, -0.0480, -0.1963, -2.3431,  0.3283,  0.8623, -0.8529,\n",
       "          -0.1996, -0.4762,  1.2222,  1.2832, -0.4256, -1.6960,  0.6840,  0.0070,\n",
       "          -0.3149, -0.4779,  0.4880,  0.7247],\n",
       "         [ 0.4527,  0.3324, -0.2172,  0.8675,  1.8041, -0.1494,  0.4023,  0.8050,\n",
       "           0.2328,  0.2276, -1.0807, -0.9454,  0.5339,  0.4062,  0.1355, -0.3932,\n",
       "           0.4008,  0.3637, -0.6990, -0.3630],\n",
       "         [-0.7426,  0.2416, -0.1481,  0.4526, -0.1475,  0.2986,  0.4692, -0.5901,\n",
       "           0.2702,  0.7704,  0.7214,  0.8933,  0.6754, -1.3022,  0.4748, -0.6819,\n",
       "          -0.3495,  1.3978, -0.6507, -0.2888],\n",
       "         [-1.5412,  1.0971,  0.1691, -0.6783, -0.2612, -0.0357, -0.2496, -1.0299,\n",
       "           0.9435,  0.4542,  0.8875,  0.8600, -0.6343,  0.1254, -0.6042,  0.2729,\n",
       "          -0.5972,  0.1899,  0.9409, -0.0332]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.2861,  1.5214,  2.4117, -2.2645, -1.5987,  2.1530, -1.9045,  3.7350],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.1689, -0.8619, -0.6452,  0.4106,  1.4453,  0.4537,  0.7401,  1.2044]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.3926], requires_grad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
