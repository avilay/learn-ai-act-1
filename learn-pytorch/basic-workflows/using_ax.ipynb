{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from dataclasses import dataclass\n",
    "import os.path as path\n",
    "\n",
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ax.service.managed_loop import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "DATAROOT = path.expanduser(\"~/mldata/pytorch\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xform = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "datapath = path.join(DATAROOT, \"fashion-mnist\")\n",
    "train_val_set = tv.datasets.FashionMNIST(datapath, download=True, train=True, transform=xform)\n",
    "train_size = int(len(train_val_set) * 0.8)\n",
    "val_size = len(train_val_set) - train_size\n",
    "trainset, valset = t.utils.data.random_split(train_val_set, [train_size, val_size])\n",
    "testset = tv.datasets.FashionMNIST(datapath, download=True, train=False, transform=xform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = t.nn.Sequential(OrderedDict([\n",
    "        (\"flatten\", t.nn.Flatten()),\n",
    "        (\"fc1\", t.nn.Linear(784, 128)),\n",
    "        (\"relu1\", t.nn.ReLU()),\n",
    "        (\"fc2\", t.nn.Linear(128, 64)),\n",
    "        (\"relu2\", t.nn.ReLU()),\n",
    "        (\"fc3\", t.nn.Linear(64, 32)),\n",
    "        (\"relu3\", t.nn.ReLU()),\n",
    "        (\"logits\", t.nn.Linear(32, 10))\n",
    "    ]))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, targets):\n",
    "    assert outputs.shape[0] == targets.shape[0]\n",
    "    predictions = t.argmax(outputs, dim=1)\n",
    "    correct = t.sum(predictions == targets).item()\n",
    "    return correct / targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Hyperparams:\n",
    "    batch_size: int = 10\n",
    "    epochs: int = 10\n",
    "    learning_rate: float = 0.0001\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"learning_rate\": self.learning_rate\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, loss_fn, epochs, trainloader, valloader):\n",
    "    model = model.to(DEVICE)\n",
    "    for epoch in range(epochs):\n",
    "        # Process the training set\n",
    "        model.train()\n",
    "        with t.enable_grad():\n",
    "            for images, targets in trainloader:\n",
    "                images = images.to(DEVICE)\n",
    "                targets = targets.to(DEVICE)\n",
    "\n",
    "                optim.zero_grad()\n",
    "                outputs = model.forward(images)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "    # Calculate the validation metrics\n",
    "    val_outputs = t.empty(0, 10)\n",
    "    val_targets = t.tensor([], dtype=t.long)\n",
    "    model.eval()\n",
    "    with t.no_grad():\n",
    "        for images, targets in valloader:\n",
    "            images = images.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            val_outputs = t.cat((val_outputs, outputs.detach()))\n",
    "            val_targets = t.cat((val_targets, targets.detach()))\n",
    "    val_acc = accuracy(val_outputs, val_targets)\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(hparams):\n",
    "    hparams = Hyperparams(**hparams)\n",
    "    model = create_model()\n",
    "    optim = t.optim.SGD(model.parameters(), lr=hparams.learning_rate)\n",
    "    loss_fn = t.nn.CrossEntropyLoss()\n",
    "    trainloader = t.utils.data.DataLoader(trainset, batch_size=hparams.batch_size, shuffle=True)\n",
    "    valloader = t.utils.data.DataLoader(valset, batch_size=5000)\n",
    "    val_acc = train(model, optim, loss_fn, hparams.epochs, trainloader, valloader)\n",
    "    return {\"accuracy\": (val_acc, 0.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-15 22:37:19] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-15 22:37:20] ax.service.managed_loop: Started full optimization with 20 steps.\n",
      "[INFO 03-15 22:37:20] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-15 22:40:25] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 03-15 22:43:19] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-15 22:47:37] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-15 22:51:48] ax.service.managed_loop: Running optimization trial 5...\n",
      "[INFO 03-15 22:54:15] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-15 22:58:11] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-15 23:01:08] ax.service.managed_loop: Running optimization trial 8...\n",
      "[INFO 03-15 23:04:31] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-15 23:07:06] ax.service.managed_loop: Running optimization trial 10...\n",
      "[INFO 03-15 23:10:42] ax.service.managed_loop: Running optimization trial 11...\n",
      "[INFO 03-15 23:13:17] ax.service.managed_loop: Running optimization trial 12...\n",
      "[INFO 03-15 23:17:10] ax.service.managed_loop: Running optimization trial 13...\n",
      "[INFO 03-15 23:20:30] ax.service.managed_loop: Running optimization trial 14...\n",
      "[INFO 03-15 23:24:18] ax.service.managed_loop: Running optimization trial 15...\n",
      "[INFO 03-15 23:27:33] ax.service.managed_loop: Running optimization trial 16...\n",
      "[INFO 03-15 23:30:40] ax.service.managed_loop: Running optimization trial 17...\n",
      "[INFO 03-15 23:35:08] ax.service.managed_loop: Running optimization trial 18...\n",
      "[INFO 03-15 23:38:36] ax.service.managed_loop: Running optimization trial 19...\n",
      "[INFO 03-15 23:42:36] ax.service.managed_loop: Running optimization trial 20...\n"
     ]
    }
   ],
   "source": [
    "hparams = [\n",
    "    {\"name\": \"batch_size\", \"type\": \"choice\", \"value_type\": \"int\", \"values\": [16, 32, 64]},\n",
    "    {\"name\": \"epochs\", \"type\": \"range\", \"value_type\": \"int\", \"bounds\": [7, 13]},\n",
    "    {\"name\": \"learning_rate\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True}\n",
    "]\n",
    "\n",
    "best_params, values, experiment, model = optimize(\n",
    "    hparams, \n",
    "    evaluation_function=train_evaluate, \n",
    "    objective_name=\"accuracy\",\n",
    "    total_trials=5  # default is 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 13, 'learning_rate': 0.25718724285671446, 'batch_size': 32}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.88525}, {'accuracy': {'accuracy': 0.0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('ai': venv)",
   "language": "python",
   "name": "python37464bitaivenvb38a7d5ca9a74889b5da00942c4b631c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
