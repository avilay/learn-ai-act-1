{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.utils.data as td\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Stuff\n",
    "In Pytorch there are two main classes for processing data, `Dataset` and `DataLoader`. Think of `Dataset` as representing the entire dataset, whether or not it fits in memory is irrelvant. `DataLoader` takes in a dataset and doles out batches of instances that it pulls from the dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Model\n",
    "\n",
    "At its simplest, the `DataLoader` needs a `Dataset` and a `Sampler` to sample from that dataset. Also, the `Sampler` will need access to the dataset so it can know the total number of available instances.\n",
    "\n",
    "![concept_model](./imgs/concept_model.png)\n",
    "\n",
    "In reality a way to batch the samples is also needed. So `DataLoader` ships with a copule of reasonable defaults.\n",
    "![default](./imgs/default.png)\n",
    "\n",
    "The builtin `BatchSampler` can be configured with 2 parameters - `batch_size` and `drop_last`. \n",
    "\n",
    "Instead of the default `SequentialSampler`, I can choose to use the builtin `RandomSampler` by setting the `shuffle=True` argument.\n",
    "![random](./imgs/random.png)\n",
    "\n",
    "I can also use my own custom sampler that the batcher will automatically wrap. This is done by passing my custom sampler object in the `sampler` argument.\n",
    "![sampler](./imgs/sampler.png)\n",
    "\n",
    "I can get rid of the batcher entirely if I so choose, by setting the `batch_size=None`.\n",
    "![nobatcher](./imgs/nobatcher.png)\n",
    "\n",
    "Or, substitute it with my custom batcher by passing my custom batcher object in the `batch_sampler` argument.\n",
    "![custom_batcher](./imgs/custom_batcher.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "In order to yield batches, dataloader first randomly samples instances from the dataset, and then collates these instances into a single batch of whatever size the caller specified, before yielding to the caller. While these defaults are good for most cases, both the sampling and batching operations are heavily customizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "If we think of datasets as indexed containers of data, pretty much like a `list` or a `dict`, we can think of samplers as objects that decide which index to read next. PyTorch as a bunch of built-in samplers like `SequentialSampler`, `RandomSampler`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dl(dl):\n",
    "    print(\"\\n\")\n",
    "    print(\"sampler: \", type(dl.sampler))\n",
    "    print(\"batch size: \", dl.batch_size)\n",
    "    print(\"batch sampler: \", type(dl.batch_sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockDataset(td.Dataset):\n",
    "    def __init__(self, size=100):\n",
    "        super().__init__()\n",
    "        self._size = size\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 "
     ]
    }
   ],
   "source": [
    "sampler = td.SequentialSampler(MockDataset(10))\n",
    "for idx in sampler:\n",
    "    print(idx, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 8 9 2 6 1 5 0 3 4 "
     ]
    }
   ],
   "source": [
    "sampler = td.RandomSampler(MockDataset(10))\n",
    "for idx in sampler:\n",
    "    print(idx, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also implement my own sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseSampler(td.Sampler):\n",
    "    def __init__(self, data_source):\n",
    "        super().__init__(data_source)\n",
    "        self._len = len(data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from range(self._len-1, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 8 7 6 5 4 3 2 1 0 "
     ]
    }
   ],
   "source": [
    "sampler = ReverseSampler(MockDataset(10))\n",
    "for idx in sampler:\n",
    "    print(idx, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default `DataLoader` will create a sequential sampler. If I set the `shuffle` arg to `True` it will create a `RandomSampler`. And of course I can specify my custom sampler if I want. But I cannot specify my custom sampler and at the same time tell the data loader to use the `RandomSampler` by setting `shuffle=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.SequentialSampler'>\n",
      "batch size:  1\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "dl = td.DataLoader(MockDataset())\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.RandomSampler'>\n",
      "batch size:  1\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "dl = td.DataLoader(MockDataset(), shuffle=True)\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sampler:  <class '__main__.ReverseSampler'>\n",
      "batch size:  1\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MockDataset()\n",
    "dl = td.DataLoader(ds, sampler=ReverseSampler(ds))\n",
    "print_dl(dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampler option is mutually exclusive with shuffle\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ds = MockDataset()\n",
    "    dl = td.DataLoader(ds, sampler=ReverseSampler(ds), shuffle=True)\n",
    "except ValueError as ve:\n",
    "    print(ve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching\n",
    "Samplers will return the next index to read. But often in ML we want to learn on a batch of data. For this, we need a way to batch the indexes in a list. The default `BatchSampler` does just that. It is a `Sampler` that wraps other samplers and simply collects the bunch of indexes before returning the entire batch. It accepts two arguments besides the sampler that it is wrapping, the `batch_size` and whether or not to drop the last batch if it has fewer samples via the `drop_last` arg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]\n",
      "[42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]\n",
      "[56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "[70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]\n",
      "[84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n",
      "[98, 99]\n"
     ]
    }
   ],
   "source": [
    "sampler = td.SequentialSampler(MockDataset())\n",
    "batcher = td.BatchSampler(sampler, batch_size=14, drop_last=False)\n",
    "for idxs in batcher:\n",
    "    print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]\n",
      "[42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]\n",
      "[56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "[70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]\n",
      "[84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n"
     ]
    }
   ],
   "source": [
    "sampler = td.SequentialSampler(MockDataset())\n",
    "batcher = td.BatchSampler(sampler, batch_size=14, drop_last=True)\n",
    "for idxs in batcher:\n",
    "    print(idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as usual I can create my custom batcher. I can use the same pattern as the built-in `BatchSampler` where it wraps an existing sampler, or I can simply implement it as a `Sampler` that accepts a `data_source` but returns a batch of samples at once instead of single samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FibnonacciBatcher(td.Sampler):\n",
    "    def __init__(self, data_source):\n",
    "        self._sampler = sampler\n",
    "        self._n1, self._n2 = 0, 1\n",
    "        self._len = len(data_source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        batch_size = self._n1 + self._n2\n",
    "        for idx in range(self._len):\n",
    "            batch.append(idx)\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "                self._n1, self._n2 = self._n2, self._n1 + self._n2\n",
    "                batch_size = self._n1 + self._n2\n",
    "        if len(batch) > 0:\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1, 2]\n",
      "[3, 4, 5]\n",
      "[6, 7, 8, 9, 10]\n",
      "[11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]\n",
      "[53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86]\n",
      "[87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "batcher = FibnonacciBatcher(MockDataset())\n",
    "for idxs in batcher:\n",
    "    print(idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the `DataLoader` will create a `BatchSampler` by passing it the sampler, `batch_size`, and `drop_last` args. The default values are `1` and `False`. The sampler can be either of the automated samplers (`SequentialSampler` or `RandomSampler`) or it can be a user specified one. I can also specify my custom batcher using the `batch_sampler` argument. But then I cannot also tell the data loader to pass in the `batch_size` and `drop_last` args to my custom sampler because it might not take these args. Also, no need to pass in any samplers via the `shuffle` or `sampler` args because my custom sampler might not be a wrapper on another sampler.\n",
    "\n",
    "I can completely turn off automated batching by specifying both the `batch_size` and `batch_sampler` to `None`. The default value of `batch_sampler` is already `None`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.SequentialSampler'>\n",
      "batch size:  1\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MockDataset()\n",
    "dl = td.DataLoader(ds)\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.SequentialSampler'>\n",
      "batch size:  2\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MockDataset()\n",
    "dl = td.DataLoader(ds, batch_size=2, drop_last=True)\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.SequentialSampler'>\n",
      "batch size:  None\n",
      "batch sampler:  <class '__main__.FibnonacciBatcher'>\n"
     ]
    }
   ],
   "source": [
    "ds = MockDataset()\n",
    "batcher = FibnonacciBatcher(ds)\n",
    "dl = td.DataLoader(ds, batch_sampler=batcher)\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_sampler option is mutually exclusive with batch_size, shuffle, sampler, and drop_last\n",
      "batch_sampler option is mutually exclusive with batch_size, shuffle, sampler, and drop_last\n",
      "batch_sampler option is mutually exclusive with batch_size, shuffle, sampler, and drop_last\n",
      "batch_sampler option is mutually exclusive with batch_size, shuffle, sampler, and drop_last\n"
     ]
    }
   ],
   "source": [
    "ds = MockDataset()\n",
    "batcher = FibnonacciBatcher(ds)\n",
    "try:\n",
    "    dl = td.DataLoader(ds, batch_sampler=batcher, batch_size=10)\n",
    "except ValueError as ve:\n",
    "    print(ve)\n",
    "\n",
    "try:\n",
    "    dl = td.DataLoader(ds, batch_sampler=batcher, drop_last=True)\n",
    "except ValueError as ve:\n",
    "    print(ve)\n",
    "\n",
    "try:\n",
    "    dl = td.DataLoader(ds, batch_sampler=batcher, shuffle=True)\n",
    "except ValueError as ve:\n",
    "    print(ve)\n",
    "\n",
    "try:\n",
    "    dl = td.DataLoader(ds, batch_sampler=batcher, sampler=ReverseSampler(ds))\n",
    "except ValueError as ve:\n",
    "    print(ve)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.SequentialSampler'>\n",
      "batch size:  None\n",
      "batch sampler:  <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "ds = MockDataset()\n",
    "dl = td.DataLoader(ds, batch_sampler=None, batch_size=None)\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collating Data\n",
    "The callable specified as the `collate_fn` takes in sample(s) yielded by the samplers and converts them to mathematical tensors. If automated batching is on, then the callable takes in a list of samples and converts them into a single tensor with the outer dim being the batch size. It will also automatically convert all numpy arrays to tensors and a couple of other utility things. When automated batching is turned off, it will be called with a single sample. The default behavior is to convert all numpy arrays to `torch.Tensor` objects and return those. Examples of this are provided after a discussion on datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "Abstraction over my entire actual underlying dataset. The underlying dataset could be a folder of images with the folder name as the label, or it can be data that is being streamed from a data warehouse, or it can be data that is read in chunks from the hard drive, etc. There are two broad types of datasets:\n",
    "\n",
    "  * **Map-Style**: When it is possible to index the underlying the dataset then it makes sense to use the map-style datasets. The dataset is expected to return one \"row\" of the underlying dataset at a time. Here the `Dataset` child class will have to implement `__getitem__` and `__len__` methods. Moreover, it has to guarantee that when called with the same key, the dataset will always return the same row.\n",
    "\n",
    "  * **Iterable-Style**: When it is not possible to index the underlying dataset, or when returning data one row at a time is too expensive, then it makes sense to implement an iterable-style dataset. Here the `IterableDataset` child class will only have to implement the `__iter__` method that needs to return an iterator.\n",
    "\n",
    "Usually if the entire underlying dataset will fit in memory we use map-style datasets. Sometimes, even when it doesn't but if the data retrieval cost is not too high, e.g., if it is reading data from the disk over the network from a database with the indexes as the primary keys, it might still be ok to use map-style datasets. But if the data retrieval cost is high, e.g., reading data from a data warehouse we might want to use the iterable-style datasets. And if the underlying dataset is a kafka-like stream, there is no option but to use iterable-style datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map-Style Datasets\n",
    "It is possible to use various samplers via the `shuffle`, `sampler`, `batch_size`, `drop_last`, and `batch_sampler` args."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMappedDataset(td.Dataset):\n",
    "    def __init__(self, n=5, m=10):\n",
    "        self._x = np.arange(n * m).reshape(m, n)\n",
    "        self._y = np.random.choice([0, 1], size=25, p=[0.7, 0.3])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._x[idx], self._y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] 0\n",
      "[3 4 5] 0\n",
      "[6 7 8] 0\n",
      "[ 9 10 11] 0\n",
      "[12 13 14] 1\n"
     ]
    }
   ],
   "source": [
    "for x, y in MyMappedDataset(n=3, m=5):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below see how the individual 1-D numpy array is converted to a 2-D `torch.Tensor` with the outer dim as the default batch size of 1. This is the default batch `collate_fn` in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2]]) tensor([0])\n",
      "tensor([[3, 4, 5]]) tensor([0])\n",
      "tensor([[6, 7, 8]]) tensor([1])\n",
      "tensor([[ 9, 10, 11]]) tensor([0])\n",
      "tensor([[12, 13, 14]]) tensor([0])\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.SequentialSampler'>\n",
      "batch size:  1\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MyMappedDataset(n=3, m=5)\n",
    "dl = td.DataLoader(ds)\n",
    "for x, y in dl:\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below I am turning automated batching off. The default `collate_fn` now just converts numpy arrays to `torch.Tensor` but there is no extra dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2]) tensor(0)\n",
      "tensor([3, 4, 5]) tensor(1)\n",
      "tensor([6, 7, 8]) tensor(0)\n",
      "tensor([ 9, 10, 11]) tensor(0)\n",
      "tensor([12, 13, 14]) tensor(1)\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.SequentialSampler'>\n",
      "batch size:  None\n",
      "batch sampler:  <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "ds = MyMappedDataset(n=3, m=5)\n",
    "dl = td.DataLoader(ds, batch_size=None)\n",
    "for x, y in dl:\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [45, 46, 47, 48, 49]]) tensor([0, 0, 0])\n",
      "tensor([[30, 31, 32, 33, 34],\n",
      "        [35, 36, 37, 38, 39],\n",
      "        [10, 11, 12, 13, 14]]) tensor([0, 1, 1])\n",
      "tensor([[40, 41, 42, 43, 44],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [25, 26, 27, 28, 29]]) tensor([1, 1, 0])\n",
      "tensor([[20, 21, 22, 23, 24]]) tensor([0])\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.RandomSampler'>\n",
      "batch size:  3\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MyMappedDataset()\n",
    "dl = td.DataLoader(ds, shuffle=True, batch_size=3)\n",
    "for x, y in dl:\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[45, 46, 47, 48, 49],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]]) tensor([0, 0, 0])\n",
      "tensor([[40, 41, 42, 43, 44],\n",
      "        [30, 31, 32, 33, 34],\n",
      "        [35, 36, 37, 38, 39]]) tensor([0, 0, 0])\n",
      "tensor([[10, 11, 12, 13, 14],\n",
      "        [25, 26, 27, 28, 29],\n",
      "        [ 5,  6,  7,  8,  9]]) tensor([0, 0, 0])\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.RandomSampler'>\n",
      "batch size:  3\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MyMappedDataset()\n",
    "dl = td.DataLoader(ds, shuffle=True, batch_size=3, drop_last=True)\n",
    "for x, y in dl:\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[45, 46, 47, 48, 49],\n",
      "        [40, 41, 42, 43, 44],\n",
      "        [35, 36, 37, 38, 39]]) tensor([0, 0, 0])\n",
      "tensor([[30, 31, 32, 33, 34],\n",
      "        [25, 26, 27, 28, 29],\n",
      "        [20, 21, 22, 23, 24]]) tensor([1, 0, 0])\n",
      "tensor([[15, 16, 17, 18, 19],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [ 5,  6,  7,  8,  9]]) tensor([0, 0, 0])\n",
      "tensor([[0, 1, 2, 3, 4]]) tensor([1])\n",
      "\n",
      "\n",
      "sampler:  <class '__main__.ReverseSampler'>\n",
      "batch size:  3\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MyMappedDataset()\n",
    "dl = td.DataLoader(ds, sampler=ReverseSampler(ds), batch_size=3)\n",
    "for x, y in dl:\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4]]) tensor([0])\n",
      "tensor([[ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14]]) tensor([0, 0])\n",
      "tensor([[15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24],\n",
      "        [25, 26, 27, 28, 29]]) tensor([0, 1, 0])\n",
      "tensor([[30, 31, 32, 33, 34],\n",
      "        [35, 36, 37, 38, 39],\n",
      "        [40, 41, 42, 43, 44],\n",
      "        [45, 46, 47, 48, 49]]) tensor([1, 1, 1, 0])\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.sampler.SequentialSampler'>\n",
      "batch size:  None\n",
      "batch sampler:  <class '__main__.FibnonacciBatcher'>\n"
     ]
    }
   ],
   "source": [
    "ds = MyMappedDataset()\n",
    "dl = td.DataLoader(ds, batch_sampler=FibnonacciBatcher(ds))\n",
    "for x, y in dl:\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterable-Style Datasets\n",
    "At their most general these datasets have no concept of indexes. Think of the underlying data source as a continuous stream. Of course I can also implement a slow dataset as an interable style dataset as well and it might be possible to index into these datasets. But considering the general case, there are no indexes. And because of this, there is no sense in having any kind of sampler or custom batching via the `shuffle`, `sampler`, or `batch_sampler` args. \n",
    "\n",
    "However, the data loader does support automated batching with these datasets where it will create an internal constant sampler and pass that to the default `BatchSampler` class along with the `batch_size` and `drop_last` args. This mostly makes sense for the streaming type underlying data sources where each row can be retrieved easily and rows are then batched together in a single batch. Though I am not sure of the scenario where `drop_last` would make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamingDataset(td.IterableDataset):\n",
    "    def __init__(self, n=5):\n",
    "        self._n = n\n",
    "\n",
    "    def __iter__(self):\n",
    "        ctr = 1\n",
    "        while True:\n",
    "            x = np.full(self._n, ctr)\n",
    "            y = np.random.choice([0, 1], size=1, p=[0.3, 0.7])[0]\n",
    "            yield x, y\n",
    "            ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1] 0\n",
      "[2 2 2 2 2] 1\n",
      "[3 3 3 3 3] 1\n",
      "[4 4 4 4 4] 1\n"
     ]
    }
   ],
   "source": [
    "for x, y in MyStreamingDataset():\n",
    "    if x[0] == 5: break\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again notice the default `collate_fn` doing its thing by adding an extra dim and converting numpy arrays to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1]]) tensor([1])\n",
      "tensor([[2, 2, 2, 2, 2]]) tensor([1])\n",
      "tensor([[3, 3, 3, 3, 3]]) tensor([1])\n",
      "tensor([[4, 4, 4, 4, 4]]) tensor([1])\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.dataloader._InfiniteConstantSampler'>\n",
      "batch size:  1\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MyStreamingDataset()\n",
    "dl = td.DataLoader(ds)\n",
    "for x, y in dl:\n",
    "    if x[0, 0] == 5: break\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3]]) tensor([0, 1, 1])\n",
      "tensor([[4, 4, 4, 4, 4],\n",
      "        [5, 5, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6]]) tensor([1, 1, 1])\n",
      "tensor([[7, 7, 7, 7, 7],\n",
      "        [8, 8, 8, 8, 8],\n",
      "        [9, 9, 9, 9, 9]]) tensor([1, 1, 1])\n",
      "tensor([[10, 10, 10, 10, 10],\n",
      "        [11, 11, 11, 11, 11],\n",
      "        [12, 12, 12, 12, 12]]) tensor([1, 0, 1])\n",
      "tensor([[13, 13, 13, 13, 13],\n",
      "        [14, 14, 14, 14, 14],\n",
      "        [15, 15, 15, 15, 15]]) tensor([0, 0, 0])\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.dataloader._InfiniteConstantSampler'>\n",
      "batch size:  3\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MyStreamingDataset()\n",
    "dl = td.DataLoader(ds, batch_size=3)\n",
    "for x, y in dl:\n",
    "    if x[0, 0] >= 15: break\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True\n",
      "object of type 'MyStreamingDataset' has no len()\n",
      "object of type 'MyStreamingDataset' has no len()\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ds = MyStreamingDataset()\n",
    "    dl = td.DataLoader(ds, shuffle=True)\n",
    "except ValueError as ve:\n",
    "    print(ve)\n",
    "\n",
    "try:\n",
    "    ds = MyStreamingDataset()\n",
    "    dl = td.DataLoader(ds, sampler=ReverseSampler(ds))\n",
    "except TypeError as te:\n",
    "    print(te) \n",
    "\n",
    "try:\n",
    "    ds = MyStreamingDataset()\n",
    "    dl = td.DataLoader(ds, batch_sampler=FibnonacciBatcher(ds))\n",
    "except TypeError as te:\n",
    "    print(te)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of illustration lets implement a slow dataset that returns a single row a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "class MySlowDataset(td.IterableDataset):\n",
    "    def __init__(self, n=5, m=100):\n",
    "        self._n = n\n",
    "        self._m = m\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(1, self._m+1):\n",
    "            x = np.full(self._n, i)\n",
    "            y = np.random.choice([0, 1], size=1, p=[0.3, 0.7])[0]\n",
    "            time.sleep(random.randint(1, 5))\n",
    "            yield x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        # even though this is not strictly needed, lets implement it to see\n",
    "        # the kind of errors that samplers will give\n",
    "        return self._m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1] 1\n",
      "[2 2 2 2 2] 1\n",
      "[3 3 3 3 3] 0\n"
     ]
    }
   ],
   "source": [
    "for x, y in MySlowDataset(m=3):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1]]) tensor([0])\n",
      "tensor([[2, 2, 2, 2, 2]]) tensor([1])\n",
      "tensor([[3, 3, 3, 3, 3]]) tensor([1])\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.dataloader._InfiniteConstantSampler'>\n",
      "batch size:  1\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MySlowDataset(m=3)\n",
    "dl = td.DataLoader(ds)\n",
    "for x, y in dl:\n",
    "    if x[0, 0] == 5: break\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3]]) tensor([1, 1, 1])\n",
      "tensor([[4, 4, 4, 4, 4],\n",
      "        [5, 5, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6]]) tensor([0, 1, 1])\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.dataloader._InfiniteConstantSampler'>\n",
      "batch size:  3\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MySlowDataset(m=6)\n",
    "dl = td.DataLoader(ds, batch_size=3)\n",
    "for x, y in dl:\n",
    "    if x[0, 0] >= 15: break\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [4, 4, 4, 4, 4]]) tensor([1, 1, 1, 0])\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.dataloader._InfiniteConstantSampler'>\n",
      "batch size:  4\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MySlowDataset(m=6)\n",
    "dl = td.DataLoader(ds, batch_size=4, drop_last=True)\n",
    "for x, y in dl:\n",
    "    if x[0, 0] >= 15: break\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader with IterableDataset: expected unspecified shuffle option, but got shuffle=True\n",
      "DataLoader with IterableDataset: expected unspecified sampler option, but got sampler=<__main__.ReverseSampler object at 0x7ff9785d5700>\n",
      "DataLoader with IterableDataset: expected unspecified batch_sampler option, but got batch_sampler=<__main__.FibnonacciBatcher object at 0x7ff9785d5370>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ds = MySlowDataset()\n",
    "    dl = td.DataLoader(ds, shuffle=True)\n",
    "except ValueError as ve:\n",
    "    print(ve)\n",
    "\n",
    "try:\n",
    "    ds = MySlowDataset()\n",
    "    dl = td.DataLoader(ds, sampler=ReverseSampler(ds))\n",
    "except ValueError as ve:\n",
    "    print(ve) \n",
    "\n",
    "try:\n",
    "    ds = MySlowDataset()\n",
    "    dl = td.DataLoader(ds, batch_sampler=FibnonacciBatcher(ds))\n",
    "except ValueError as ve:\n",
    "    print(ve)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets implement a batched slow dataset which is a more realistic scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "class MySlowBatchedDataset(td.IterableDataset):\n",
    "    def __init__(self, n=5, m=100, batch_size=10):\n",
    "        self._n = n\n",
    "        self._m = m\n",
    "        self._batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch_x = np.empty((self._batch_size, self._n))\n",
    "        batch_y = np.empty(self._batch_size)\n",
    "        next_idx = 0\n",
    "        for i in range(1, self._m + 1):\n",
    "            curr_idx = next_idx\n",
    "            batch_x[curr_idx] = np.full(self._n, i)\n",
    "            batch_y[curr_idx] = np.random.choice([0, 1], size=1, p=[0.3, 0.7])[0]\n",
    "            next_idx += 1\n",
    "            if next_idx == self._batch_size:\n",
    "                time.sleep(random.randint(1, 5))\n",
    "                yield batch_x.astype(np.float32), batch_y.astype(int)\n",
    "                batch_x = np.empty((self._batch_size, self._n))\n",
    "                batch_y = np.empty(self._batch_size)\n",
    "                next_idx = 0\n",
    "        if next_idx < self._batch_size:\n",
    "            time.sleep(random.randint(1, 5))\n",
    "            yield batch_x[:next_idx], batch_y[:next_idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        # even though this is not strictly needed, lets implement it to see\n",
    "        # the kind of errors that samplers will give\n",
    "        return self._m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [3. 3. 3. 3. 3.]] [1 0 1]\n",
      "[[4. 4. 4. 4. 4.]\n",
      " [5. 5. 5. 5. 5.]\n",
      " [6. 6. 6. 6. 6.]] [0 1 1]\n",
      "[[7. 7. 7. 7. 7.]\n",
      " [8. 8. 8. 8. 8.]\n",
      " [9. 9. 9. 9. 9.]] [1 0 1]\n",
      "[[10. 10. 10. 10. 10.]] [0.]\n"
     ]
    }
   ],
   "source": [
    "for x, y in MySlowBatchedDataset(m=10, batch_size=3):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below the default `collate_fn` for batches is doing its thing and adding an extra dim to everything. For a batched dataset this is not really needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [3., 3., 3., 3., 3.]]]) tensor([[0, 1, 1]])\n",
      "tensor([[[4., 4., 4., 4., 4.],\n",
      "         [5., 5., 5., 5., 5.],\n",
      "         [6., 6., 6., 6., 6.]]]) tensor([[0, 0, 1]])\n",
      "tensor([[[7., 7., 7., 7., 7.],\n",
      "         [8., 8., 8., 8., 8.],\n",
      "         [9., 9., 9., 9., 9.]]]) tensor([[1, 0, 1]])\n",
      "tensor([[[10., 10., 10., 10., 10.]]], dtype=torch.float64) tensor([[0.]], dtype=torch.float64)\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.dataloader._InfiniteConstantSampler'>\n",
      "batch size:  1\n",
      "batch sampler:  <class 'torch.utils.data.sampler.BatchSampler'>\n"
     ]
    }
   ],
   "source": [
    "ds = MySlowBatchedDataset(m=10, batch_size=3)\n",
    "dl = td.DataLoader(ds)\n",
    "for x, y in dl:\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By turning of automated batching, the default `collate_fn` for single rows gets into action and all it does is convert numpy arrays to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3., 3.]]) tensor([1, 0, 1])\n",
      "tensor([[4., 4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6., 6.]]) tensor([1, 0, 1])\n",
      "tensor([[7., 7., 7., 7., 7.],\n",
      "        [8., 8., 8., 8., 8.],\n",
      "        [9., 9., 9., 9., 9.]]) tensor([0, 0, 1])\n",
      "tensor([[10., 10., 10., 10., 10.]], dtype=torch.float64) tensor([0.], dtype=torch.float64)\n",
      "\n",
      "\n",
      "sampler:  <class 'torch.utils.data.dataloader._InfiniteConstantSampler'>\n",
      "batch size:  None\n",
      "batch sampler:  <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "ds = MySlowBatchedDataset(m=10, batch_size=3)\n",
    "dl = td.DataLoader(ds, batch_size=None)\n",
    "for x, y in dl:\n",
    "    print(x, y)\n",
    "\n",
    "print_dl(dl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:41:22) [Clang 13.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c957e4ca480fc31da01b2648e097b4e55db834b6351128636991f182c884d81e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
