{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os.path as path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "import torchtext as tt\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from haikunator import Haikunator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAROOT = path.expanduser(\"~/mldata/pytorch\")\n",
    "DEVICE = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlruns_dir = path.expanduser(\"~/mlruns\")\n",
    "mlflow.set_tracking_uri(mlruns_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pickled datasets. Loading from there.\n"
     ]
    }
   ],
   "source": [
    "agnews_path = path.join(DATAROOT, \"agnews\")\n",
    "trainset_path = path.join(agnews_path, \"trainset.pkl\")\n",
    "testset_path = path.join(agnews_path, \"testset.pkl\")\n",
    "\n",
    "if path.exists(trainset_path):\n",
    "    print(\"Found pickled datasets. Loading from there.\")\n",
    "    with open(trainset_path, \"rb\") as f:\n",
    "        train_val_set = pickle.load(f)\n",
    "    with open(testset_path, \"rb\") as f:\n",
    "        testset = pickle.load(f)\n",
    "else:\n",
    "    print(\"Downloading and serializing datasets.\")\n",
    "    train_val_set, testset = tt.datasets.AG_NEWS(agnews_path)\n",
    "    with open(trainset_path, \"wb\") as f:\n",
    "        pickle.dump(train_val_set, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(testset_path, \"wb\") as f:\n",
    "        pickle.dump(testset, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000 7600\n"
     ]
    }
   ],
   "source": [
    "print(len(train_val_set), len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108000 12000\n"
     ]
    }
   ],
   "source": [
    "trainsize = int(len(train_val_set) * 0.9)\n",
    "valsize = len(train_val_set) - trainsize\n",
    "trainset, valset = t.utils.data.random_split(train_val_set, [trainsize, valsize])\n",
    "print(len(trainset), len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = train_val_set.get_vocab()\n",
    "n_classes = len(train_val_set.get_labels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "Lets learn the embeddings along with the rest of the NN. The NN architecture is very simple, a couple of fully connected layers with ReLU activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Hyperparams:\n",
    "    max_seq_len: int = 50\n",
    "    embedding_dim: int = 100\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 7\n",
    "    learning_rate: float = 0.001\n",
    "    clip: float = 5.0\n",
    "    l2: float = 0.0\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"max_seq_len\": self.max_seq_len,\n",
    "            \"embedding_dim\": self.embedding_dim,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"clip\": self.clip,\n",
    "            \"l2\": self.l2\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch_processor(max_seq_len):\n",
    "    def process_batch(batch):\n",
    "        targets = t.empty(len(batch), dtype=t.long)\n",
    "        contents = t.zeros(len(batch), max_seq_len, dtype=t.long)\n",
    "        for idx, (target, content) in enumerate(batch):\n",
    "            targets[idx] = target\n",
    "            seq_len = content.shape[0]\n",
    "            if seq_len >= max_seq_len:\n",
    "                contents[idx] = content[:max_seq_len]\n",
    "            else:\n",
    "                contents[idx][:seq_len] = content\n",
    "        return contents, targets\n",
    "    return process_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple(t.nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, n_classes, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = t.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.fc1 = t.nn.Linear(max_seq_len * embedding_dim, 1024)\n",
    "        self.fc2 = t.nn.Linear(1024, 64)\n",
    "        self.logits = t.nn.Linear(64, n_classes)\n",
    "\n",
    "    def forward(self, contents):\n",
    "        batch_size = contents.shape[0]\n",
    "        x = self.embedding(contents)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.logits(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Hyperparams()\n",
    "model = Simple(len(vocab), hparams.max_seq_len, n_classes, hparams.embedding_dim)\n",
    "dl = t.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=build_batch_processor(hparams.max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents, targets = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(contents)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, targets):\n",
    "    assert outputs.shape[0] == targets.shape[0]\n",
    "    predictions = t.argmax(outputs, dim=1)\n",
    "    correct = t.sum(predictions == targets).item()\n",
    "    return correct / targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, loss_fn, epochs, trainloader, valloader, hparams):\n",
    "    run_name = Haikunator().haikunate()\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params(hparams.to_dict())\n",
    "        for epoch in range(epochs):\n",
    "            # Process the training set\n",
    "            train_losses = []\n",
    "            train_outputs = t.empty(0, n_classes).to(DEVICE)\n",
    "            train_targets = t.tensor([], dtype=t.long).to(DEVICE)\n",
    "            model.train()\n",
    "            with t.enable_grad():\n",
    "                for images, targets in trainloader:\n",
    "                    images = images.to(DEVICE)\n",
    "                    targets = targets.to(DEVICE)\n",
    "\n",
    "                    optim.zero_grad()\n",
    "                    outputs = model.forward(images)\n",
    "                    loss = loss_fn(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    # printed = print_param_stats(\"BEFORE CLIPPING\", model, hparams.clip)\n",
    "                    t.nn.utils.clip_grad_value_(model.parameters(), hparams.clip)\n",
    "                    # if printed: print_param_stats(\"AFTER CLIPPING\", model, float(\"-inf\"))\n",
    "                    optim.step()\n",
    "\n",
    "                    train_losses.append(loss.detach().item())\n",
    "                    train_outputs = t.cat((train_outputs, outputs.detach()))\n",
    "                    train_targets = t.cat((train_targets, targets.detach()))\n",
    "            train_loss = np.mean(train_losses)\n",
    "            train_acc = accuracy(train_outputs, train_targets)\n",
    "\n",
    "            # Calculate the validation metrics\n",
    "            val_losses = []\n",
    "            val_outputs = t.empty(0, n_classes).to(DEVICE)\n",
    "            val_targets = t.tensor([], dtype=t.long).to(DEVICE)\n",
    "            model.eval()\n",
    "            with t.no_grad():\n",
    "                for images, targets in valloader:\n",
    "                    images = images.to(DEVICE)\n",
    "                    targets = targets.to(DEVICE)\n",
    "                    outputs = model(images)\n",
    "                    loss = loss_fn(outputs, targets)\n",
    "                    val_losses.append(loss.detach().item())\n",
    "                    val_outputs = t.cat((val_outputs, outputs.detach()))\n",
    "                    val_targets = t.cat((val_targets, targets.detach()))\n",
    "            val_loss = np.mean(val_losses)\n",
    "            val_acc = accuracy(val_outputs, val_targets)\n",
    "\n",
    "            mlflow.log_metric(\"train_loss\", np.around(train_loss, 3), step=epoch)\n",
    "            mlflow.log_metric(\"val_loss\", np.around(val_loss, 3), step=epoch)\n",
    "            mlflow.log_metric(\"train_acc\", np.around(train_acc, 2), step=epoch)\n",
    "            mlflow.log_metric(\"val_acc\", np.around(val_acc, 2), step=epoch)\n",
    "            print(f\"\\nEpoch {epoch}:\")\n",
    "            print(f\"Loss: train={train_loss:.3f}, validation={val_loss:.3f}\")\n",
    "            print(f\"Accuracy: train={train_acc:.3f}, validaiton={val_acc:.3f}\")\n",
    "\n",
    "        mlflow.pytorch.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Simple\")\n",
    "hparams = Hyperparams()\n",
    "model = Simple(len(vocab), hparams.max_seq_len, n_classes, hparams.embedding_dim)\n",
    "optim = t.optim.Adam(model.parameters(), lr=hparams.learning_rate)\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "trainloader = t.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=hparams.batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=build_batch_processor(hparams.max_seq_len)\n",
    ")\n",
    "valloader = t.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=5000,\n",
    "    collate_fn=build_batch_processor(hparams.max_seq_len)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optim, loss_fn, hparams.epochs, trainloader, valloader, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was terribly overfit. I can probably try to do the following things:\n",
    "  * Regularization techniques like L2 or dropouts\n",
    "  * Data augmentation (how?)\n",
    "\n",
    "But time for second experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "Lets use GloVe word vectors instead of trying to learn the embeddings from scratch. But we'll still use a relatively simple architecture of fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_datapath = path.join(DATAROOT, \"glove\")\n",
    "glove = tt.vocab.GloVe(name=\"6B\", dim=100, cache=glove_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.load_vectors(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGlove(t.nn.Module):\n",
    "    def __init__(self, max_seq_len, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = t.nn.Embedding.from_pretrained(vocab.vectors)\n",
    "        self.fc1 = t.nn.Linear(max_seq_len * embedding_dim, 1024)\n",
    "        self.fc2 = t.nn.Linear(1024, 64)\n",
    "        self.logits = t.nn.Linear(64, n_classes)\n",
    "\n",
    "    def forward(self, contents):\n",
    "        batch_size = contents.shape[0]\n",
    "        x = self.embedding(contents)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.logits(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `embedding` layer is frozen. Verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Hyperparams()\n",
    "model = SimpleGlove(hparams.max_seq_len, hparams.embedding_dim)\n",
    "\n",
    "print(\"embedding layer -\")\n",
    "for param in model.embedding.parameters():\n",
    "    print(param.requires_grad)\n",
    "\n",
    "print(\"\\nfc1 layer -\")\n",
    "for param in model.fc1.parameters():\n",
    "    print(param.requires_grad)\n",
    "\n",
    "print(\"\\nfc2 layer -\")\n",
    "for param in model.fc2.parameters():\n",
    "    print(param.requires_grad)\n",
    "\n",
    "print(\"\\nlogit layer -\")\n",
    "for param in model.logits.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"SimpleGlove\")\n",
    "hparams = Hyperparams()\n",
    "model = SimpleGlove(hparams.max_seq_len, hparams.embedding_dim)\n",
    "optim = t.optim.Adam(model.parameters(), lr=hparams.learning_rate)\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "trainloader = t.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=hparams.batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=build_batch_processor(hparams.max_seq_len)\n",
    ")\n",
    "valloader = t.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=5000,\n",
    "    collate_fn=build_batch_processor(hparams.max_seq_len)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optim, loss_fn, hparams.epochs, trainloader, valloader, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better than last time, but still overfitting like crazy. Time for experiment 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "Use a RNN instead of an FCN along with GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnGlove(t.nn.Module):\n",
    "    def __init__(self, max_seq_len, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = t.nn.Embedding.from_pretrained(vocab.vectors)\n",
    "        self.rnn = t.nn.RNN(input_size=embedding_dim, hidden_size=128, num_layers=1, batch_first=True, nonlinearity=\"tanh\")\n",
    "        self.logits = t.nn.Linear(128, n_classes)\n",
    "        \n",
    "    def forward(self, contents):\n",
    "        # contents \\in batch_size x max_seq_len\n",
    "        # x \\in batch_size x max_seq_len x embedding_dim\n",
    "        # h \\in 1 x batch_size x hidden_size => batch_size x hidden_size\n",
    "        # logits \\in batch_size x n_classes\n",
    "        x = self.embedding(contents)\n",
    "        _, h = self.rnn(x)\n",
    "        h = h.squeeze()\n",
    "        return self.logits(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Hyperparams()\n",
    "model = SimpleGlove(hparams.max_seq_len, hparams.embedding_dim)\n",
    "dl = t.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=build_batch_processor(hparams.max_seq_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents, targets = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(contents)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'RnnGlove' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"RnnGlove\")\n",
    "hparams = Hyperparams(\n",
    "    max_seq_len=50,\n",
    "    embedding_dim=100,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    learning_rate=0.00008,\n",
    "    clip=0.9,\n",
    "    l2=0.01\n",
    ")\n",
    "model = RnnGlove(hparams.max_seq_len, hparams.embedding_dim)\n",
    "optim = t.optim.Adam(model.parameters(), lr=hparams.learning_rate)\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "trainloader = t.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=hparams.batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=build_batch_processor(hparams.max_seq_len)\n",
    ")\n",
    "valloader = t.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=5000,\n",
    "    collate_fn=build_batch_processor(hparams.max_seq_len)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:\n",
      "Loss: train=0.741, validation=0.493\n",
      "Accuracy: train=0.692, validaiton=0.849\n",
      "\n",
      "Epoch 1:\n",
      "Loss: train=0.473, validation=0.465\n",
      "Accuracy: train=0.856, validaiton=0.851\n",
      "\n",
      "Epoch 2:\n",
      "Loss: train=0.418, validation=0.381\n",
      "Accuracy: train=0.872, validaiton=0.879\n",
      "\n",
      "Epoch 3:\n",
      "Loss: train=0.374, validation=0.350\n",
      "Accuracy: train=0.883, validaiton=0.888\n",
      "\n",
      "Epoch 4:\n",
      "Loss: train=0.360, validation=0.346\n",
      "Accuracy: train=0.885, validaiton=0.888\n",
      "\n",
      "Epoch 5:\n",
      "Loss: train=0.353, validation=0.342\n",
      "Accuracy: train=0.886, validaiton=0.888\n",
      "\n",
      "Epoch 6:\n",
      "Loss: train=0.346, validation=0.347\n",
      "Accuracy: train=0.887, validaiton=0.885\n",
      "\n",
      "Epoch 7:\n",
      "Loss: train=0.345, validation=0.353\n",
      "Accuracy: train=0.888, validaiton=0.885\n",
      "\n",
      "Epoch 8:\n",
      "Loss: train=0.345, validation=0.337\n",
      "Accuracy: train=0.887, validaiton=0.889\n",
      "\n",
      "Epoch 9:\n",
      "Loss: train=0.342, validation=0.332\n",
      "Accuracy: train=0.888, validaiton=0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RnnGlove. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "train(model, optim, loss_fn, hparams.epochs, trainloader, valloader, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param_stats(caption, model, threshold):\n",
    "    to_print = False\n",
    "\n",
    "    for param in model.rnn.parameters():\n",
    "        if to_print: break\n",
    "        if t.max(param.grad) >= threshold or t.min(param.grad) <= -threshold:\n",
    "            to_print = True\n",
    "    \n",
    "    for param in model.logits.parameters():\n",
    "        if to_print: break\n",
    "        if t.max(param.grad) >= threshold or t.min(param.grad) <= -threshold:\n",
    "            to_print = True\n",
    "    \n",
    "    if not to_print: return False\n",
    "\n",
    "    print(f\"\\n{caption} ---\")\n",
    "    print(\"embedding layer -\")\n",
    "    for param in model.embedding.parameters():\n",
    "        print(param.requires_grad, param.shape)\n",
    "\n",
    "    print(\"\\nrnn layer -\")\n",
    "    for param in model.rnn.parameters():\n",
    "        print(param.requires_grad, param.shape, t.min(param.grad), t.max(param.grad))\n",
    "\n",
    "    print(\"\\nlogit layer -\")\n",
    "    for param in model.logits.parameters():\n",
    "        print(param.requires_grad, param.shape, t.min(param.grad), t.max(param.grad))\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
