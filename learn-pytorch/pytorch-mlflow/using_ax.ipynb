{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from dataclasses import dataclass\n",
    "import os.path as path\n",
    "\n",
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from haikunator import Haikunator\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from ax.service.managed_loop import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "DATAROOT = path.expanduser(\"~/mldata/pytorch\")\n",
    "EXPERIMENT_NAME = \"FashionAutoTune\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlruns_dir = path.expanduser(\"~/mlruns\")\n",
    "mlflow.set_tracking_uri(mlruns_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xform = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "datapath = path.join(DATAROOT, \"fashion-mnist\")\n",
    "train_val_set = tv.datasets.FashionMNIST(datapath, download=True, train=True, transform=xform)\n",
    "train_size = int(len(train_val_set) * 0.8)\n",
    "val_size = len(train_val_set) - train_size\n",
    "trainset, valset = t.utils.data.random_split(train_val_set, [train_size, val_size])\n",
    "testset = tv.datasets.FashionMNIST(datapath, download=True, train=False, transform=xform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = t.nn.Sequential(OrderedDict([\n",
    "        (\"flatten\", t.nn.Flatten()),\n",
    "        (\"fc1\", t.nn.Linear(784, 128)),\n",
    "        (\"relu1\", t.nn.ReLU()),\n",
    "        (\"fc2\", t.nn.Linear(128, 64)),\n",
    "        (\"relu2\", t.nn.ReLU()),\n",
    "        (\"fc3\", t.nn.Linear(64, 32)),\n",
    "        (\"relu3\", t.nn.ReLU()),\n",
    "        (\"logits\", t.nn.Linear(32, 10))\n",
    "    ]))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, targets):\n",
    "    assert outputs.shape[0] == targets.shape[0]\n",
    "    predictions = t.argmax(outputs, dim=1)\n",
    "    correct = t.sum(predictions == targets).item()\n",
    "    return correct / targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Hyperparams:\n",
    "    batch_size: int = 10\n",
    "    epochs: int = 10\n",
    "    learning_rate: float = 0.0001\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"learning_rate\": np.around(self.learning_rate, 3)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, loss_fn, epochs, trainloader, valloader, hparams):\n",
    "    run_name = Haikunator().haikunate()\n",
    "    print(f\"Starting run {run_name}\")\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params(hparams.to_dict())\n",
    "        for epoch in range(epochs):\n",
    "            # Process the training set\n",
    "            model.train()\n",
    "            with t.enable_grad():\n",
    "                for images, targets in trainloader:\n",
    "                    images = images.to(DEVICE)\n",
    "                    targets = targets.to(DEVICE)\n",
    "\n",
    "                    optim.zero_grad()\n",
    "                    outputs = model.forward(images)\n",
    "                    loss = loss_fn(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    optim.step()\n",
    "\n",
    "            # Calculate the validation metrics for this epoch\n",
    "            val_outputs = t.empty(0, 10).to(DEVICE)\n",
    "            val_targets = t.tensor([], dtype=t.long).to(DEVICE)\n",
    "            model.eval()\n",
    "            with t.no_grad():\n",
    "                for images, targets in valloader:\n",
    "                    images = images.to(DEVICE)\n",
    "                    targets = targets.to(DEVICE)\n",
    "                    outputs = model(images)\n",
    "                    loss = loss_fn(outputs, targets)\n",
    "                    val_outputs = t.cat((val_outputs, outputs.detach()))\n",
    "                    val_targets = t.cat((val_targets, targets.detach()))\n",
    "            val_acc = accuracy(val_outputs, val_targets)\n",
    "            mlflow.log_metric(\"val_acc\", np.around(val_acc, 2), step=epoch)\n",
    "    return val_acc  # this is the final val_acc of the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(hparams):\n",
    "    hparams = Hyperparams(**hparams)\n",
    "    model = create_model()\n",
    "    optim = t.optim.SGD(model.parameters(), lr=hparams.learning_rate)\n",
    "    loss_fn = t.nn.CrossEntropyLoss()\n",
    "    trainloader = t.utils.data.DataLoader(trainset, batch_size=hparams.batch_size, shuffle=True)\n",
    "    valloader = t.utils.data.DataLoader(valset, batch_size=5000)\n",
    "    val_acc = train(model, optim, loss_fn, hparams.epochs, trainloader, valloader, hparams)\n",
    "    return {\"accuracy\": (val_acc, 0.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-20 19:07:13] ax.modelbridge.dispatch_utils: Using Sobol generation strategy.\n",
      "[INFO 03-20 19:07:13] ax.service.managed_loop: Started full optimization with 5 steps.\n",
      "[INFO 03-20 19:07:13] ax.service.managed_loop: Running optimization trial 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run plain-night-9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-20 19:09:53] ax.service.managed_loop: Running optimization trial 2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run green-silence-3849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-20 19:12:56] ax.service.managed_loop: Running optimization trial 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run still-wind-1821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-20 19:15:20] ax.service.managed_loop: Running optimization trial 4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run fragrant-bird-8937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-20 19:16:59] ax.service.managed_loop: Running optimization trial 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run quiet-river-9063\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "hparams = [\n",
    "    {\"name\": \"batch_size\", \"type\": \"choice\", \"value_type\": \"int\", \"values\": [16, 32, 64]},\n",
    "    {\"name\": \"epochs\", \"type\": \"range\", \"value_type\": \"int\", \"bounds\": [7, 13]},\n",
    "    {\"name\": \"learning_rate\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True}\n",
    "]\n",
    "\n",
    "best_params, values, experiment, model = optimize(\n",
    "    hparams, \n",
    "    evaluation_function=train_evaluate, \n",
    "    objective_name=\"accuracy\",\n",
    "    total_trials=5  # default is 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 12, 'learning_rate': 0.0020909231008650105, 'batch_size': 32}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.83475}, {'accuracy': {'accuracy': 0.0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
