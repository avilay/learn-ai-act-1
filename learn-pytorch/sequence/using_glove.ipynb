{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca504982-4734-406f-b42c-82e2c1f2f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24cbdfe5-2a79-4855-bc18-10977a6bb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from imdb.data import get_vocab\n",
    "import torchtext as tt\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f34b57-aa9d-4099-8c39-4994269abdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAROOT = Path.home() / \"mldata\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b3ab7-92fe-4949-8056-17ebc7c821fa",
   "metadata": {},
   "source": [
    "# Glove Vectors\n",
    "\n",
    "This notebook explains how to use Glove vectors as a frozen embedding table when training. First lets get the Glove vectors, which are `Vectors` object and see how to create an embedding layer from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4fe0ac-7265-4f51-bc23-f657a18c022d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vecs = tt.vocab.GloVe(name=\"6B\", dim=50, cache=DATAROOT / \"glove\")\n",
    "len(glove_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08472cdb-884f-4616-b6ef-7cb0e7d155f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(400000, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_emb = t.nn.Embedding.from_pretrained(glove_vecs.vectors)\n",
    "glove_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d149535-d592-4bd5-a712-10267b663354",
   "metadata": {},
   "source": [
    "We will expect that a sequence that reads `[\"all\", \"hand\"]` will result in a tensor that looks like -\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\left [ \\text{vector of all} \\right ] \\\\\n",
    "\\left [ \\text{vector of hand} \\right ] \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Lets verify this. First we read the vector values directly from the glove vectors, then we pass a tensor with the indices of these two words to the embedding layer and should expect to get the same two vectors stacked on top of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f04af5-5e20-46bc-b608-93237efe03d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1925,  0.1001,  0.0638, -0.0877,  0.5222,  0.3911, -0.4198, -0.4567,\n",
       "         -0.3405, -0.1117,  0.0148,  0.3173, -0.5085, -0.1156,  0.7430,  0.0976,\n",
       "          0.3441, -0.1213, -0.1694, -0.8409, -0.1123,  0.4060,  0.7680,  0.0911,\n",
       "          0.1078, -1.2673, -0.5771, -0.3621,  0.3482, -0.7546,  4.0426,  0.9497,\n",
       "         -0.2267, -0.3578,  0.3413,  0.1307,  0.2305, -0.0370, -0.2589,  0.1298,\n",
       "         -0.3903, -0.0496,  0.4577,  0.5678, -0.4617,  0.4193, -0.5492,  0.0812,\n",
       "         -0.3049, -0.3051],\n",
       "        [ 0.0881, -0.4270,  0.2128, -0.4614,  0.8865,  0.3196, -0.0095,  0.1226,\n",
       "         -0.0112, -0.2113, -0.1177,  0.0859, -0.5400,  0.2767, -0.0742,  0.1130,\n",
       "         -0.3136, -0.3067,  0.1383, -0.9979, -0.1051,  0.5650,  0.3011, -0.6091,\n",
       "          0.2153, -1.9955, -0.2307,  0.3617,  0.3657, -0.8359,  3.1593,  0.3848,\n",
       "         -0.5879,  0.3027, -0.0801,  0.7723,  0.1453,  0.5484,  0.1391, -0.1582,\n",
       "          0.3756,  0.6432, -0.3582,  0.2687,  0.3704, -0.1284,  0.1405, -0.3739,\n",
       "         -0.2409, -0.8076]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vecs.get_vecs_by_tokens([\"all\", \"hand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d88885-b1c8-4cf1-a8a9-1c2e6d1474c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 823\n"
     ]
    }
   ],
   "source": [
    "all_idx = glove_vecs.stoi[\"all\"]\n",
    "hand_idx = glove_vecs.stoi[\"hand\"]\n",
    "print(all_idx, hand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6851d84c-a5cf-46a1-92e5-91734d519c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1925,  0.1001,  0.0638, -0.0877,  0.5222,  0.3911, -0.4198, -0.4567,\n",
       "         -0.3405, -0.1117,  0.0148,  0.3173, -0.5085, -0.1156,  0.7430,  0.0976,\n",
       "          0.3441, -0.1213, -0.1694, -0.8409, -0.1123,  0.4060,  0.7680,  0.0911,\n",
       "          0.1078, -1.2673, -0.5771, -0.3621,  0.3482, -0.7546,  4.0426,  0.9497,\n",
       "         -0.2267, -0.3578,  0.3413,  0.1307,  0.2305, -0.0370, -0.2589,  0.1298,\n",
       "         -0.3903, -0.0496,  0.4577,  0.5678, -0.4617,  0.4193, -0.5492,  0.0812,\n",
       "         -0.3049, -0.3051],\n",
       "        [ 0.0881, -0.4270,  0.2128, -0.4614,  0.8865,  0.3196, -0.0095,  0.1226,\n",
       "         -0.0112, -0.2113, -0.1177,  0.0859, -0.5400,  0.2767, -0.0742,  0.1130,\n",
       "         -0.3136, -0.3067,  0.1383, -0.9979, -0.1051,  0.5650,  0.3011, -0.6091,\n",
       "          0.2153, -1.9955, -0.2307,  0.3617,  0.3657, -0.8359,  3.1593,  0.3848,\n",
       "         -0.5879,  0.3027, -0.0801,  0.7723,  0.1453,  0.5484,  0.1391, -0.1582,\n",
       "          0.3756,  0.6432, -0.3582,  0.2687,  0.3704, -0.1284,  0.1405, -0.3739,\n",
       "         -0.2409, -0.8076]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_emb(t.tensor([64, 823]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb915b-011b-4111-8b73-d9e8ae3252bc",
   "metadata": {},
   "source": [
    "Everything is working as it should.\n",
    "\n",
    "Now lets get the IMDB vocab. However, it is possible that there might be words in the IMDB vocab that are missing from the glove vocab. Lets check this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "325a140a-a0bb-4b3e-a1a0-bd530d90caa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_vocab, _ = get_vocab(DATAROOT)\n",
    "len(imdb_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e4ff42e-529e-4ae1-868a-13997eaefff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66922\n",
      "['\\x96', 'hadn', '****', 'camera-work', '100%', '*****', '*1/2', '#1', '$1', 'it`s']\n"
     ]
    }
   ],
   "source": [
    "missing_words = list(filter(lambda tok: tok not in glove_vecs.stoi, imdb_vocab.get_itos()))\n",
    "print(len(missing_words))\n",
    "print(missing_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1e083-c89b-416a-a17c-b224426b750e",
   "metadata": {},
   "source": [
    "Out of roughly 147K words in IMDB vocab, around 70K are missing from the glove vocab, i.e., half of the vocab is missing. If I get a sequence that reads \"all hadn\" then what should I pass to the embedding layer? The first number is the index of \"all\" which is 64, but what about \"hadn\"? This does not have any index at all in the Glove vectors, and therefore there is no corresponding entry in the embedding table for it. How do I handle such unknown tokens? I can do one of two things - \n",
    "  1. The `<unk>` token will have a vector of all zeros.\n",
    "  2. The `<unk>` token will have a vector that is the average of all the other vectors in the vocab.\n",
    "  \n",
    "The ctor of the `Vectors` class lets us specify this via `None`, which means use all zeros, or a callback. Now, when I call `get_vecs_by_tokens` with some unknown tokens, it will return zeros (or whetever else I configure) for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c798b0d-0581-4198-8577-51166e3b609a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1925,  0.1001,  0.0638, -0.0877,  0.5222,  0.3911, -0.4198, -0.4567,\n",
       "         -0.3405, -0.1117,  0.0148,  0.3173, -0.5085, -0.1156,  0.7430,  0.0976,\n",
       "          0.3441, -0.1213, -0.1694, -0.8409, -0.1123,  0.4060,  0.7680,  0.0911,\n",
       "          0.1078, -1.2673, -0.5771, -0.3621,  0.3482, -0.7546,  4.0426,  0.9497,\n",
       "         -0.2267, -0.3578,  0.3413,  0.1307,  0.2305, -0.0370, -0.2589,  0.1298,\n",
       "         -0.3903, -0.0496,  0.4577,  0.5678, -0.4617,  0.4193, -0.5492,  0.0812,\n",
       "         -0.3049, -0.3051],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vecs.get_vecs_by_tokens([\"all\", \"hadn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab96e73-a4c2-4942-940b-ff984f8e961f",
   "metadata": {},
   "source": [
    "But it still does not solve the problem of how do I call the embedding table with unknown tokens, they don't even have an index! The solution is to create imdb vectors, where all unknown tokens will get the `<unk>` value from glove, all known tokens will just get the corresponing glove values. E.g.,\n",
    "\n",
    "```\n",
    "imdb_vecs[\"the\"] = glove_vecs[\"the\"]\n",
    "imdb_vecs[\"hadn\"] = <unk> from glove\n",
    "imdb_vecs[\"camera-work\"] = <unk> from glove\n",
    "...\n",
    "```\n",
    "\n",
    "This means that the indices of words will get messed up, i.e., a word like \"minutes\" that exists in both vocabs might have its index be different, but the vector values will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfdd617e-48de-46ec-9421-3e2b2c4ddd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: all\n",
      "IMDB index: 36  Glove index: 64\n",
      "IMDB vector:  tensor([ 0.1925,  0.1001,  0.0638, -0.0877,  0.5222,  0.3911, -0.4198, -0.4567,\n",
      "        -0.3405, -0.1117,  0.0148,  0.3173, -0.5085, -0.1156,  0.7430,  0.0976,\n",
      "         0.3441, -0.1213, -0.1694, -0.8409, -0.1123,  0.4060,  0.7680,  0.0911,\n",
      "         0.1078, -1.2673, -0.5771, -0.3621,  0.3482, -0.7546,  4.0426,  0.9497,\n",
      "        -0.2267, -0.3578,  0.3413,  0.1307,  0.2305, -0.0370, -0.2589,  0.1298,\n",
      "        -0.3903, -0.0496,  0.4577,  0.5678, -0.4617,  0.4193, -0.5492,  0.0812,\n",
      "        -0.3049, -0.3051])\n",
      "Glove vector:  tensor([ 0.1925,  0.1001,  0.0638, -0.0877,  0.5222,  0.3911, -0.4198, -0.4567,\n",
      "        -0.3405, -0.1117,  0.0148,  0.3173, -0.5085, -0.1156,  0.7430,  0.0976,\n",
      "         0.3441, -0.1213, -0.1694, -0.8409, -0.1123,  0.4060,  0.7680,  0.0911,\n",
      "         0.1078, -1.2673, -0.5771, -0.3621,  0.3482, -0.7546,  4.0426,  0.9497,\n",
      "        -0.2267, -0.3578,  0.3413,  0.1307,  0.2305, -0.0370, -0.2589,  0.1298,\n",
      "        -0.3903, -0.0496,  0.4577,  0.5678, -0.4617,  0.4193, -0.5492,  0.0812,\n",
      "        -0.3049, -0.3051])\n",
      "\n",
      "\n",
      "Token: hadn\n",
      "IMDB index: 1874  Glove index: -1\n",
      "IMDB vector:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "Glove vector:  None\n",
      "\n",
      "\n",
      "Token: minutes\n",
      "IMDB index: 232  Glove index: 599\n",
      "IMDB vector:  tensor([ 1.6963e-01,  2.0912e-05,  5.1110e-01, -5.0768e-01,  6.9489e-01,\n",
      "        -1.1762e-01, -3.2955e-01,  5.3581e-01, -3.4780e-01,  2.9399e-01,\n",
      "        -4.4349e-01, -7.2387e-01, -5.8002e-01,  5.9233e-01,  8.1141e-01,\n",
      "        -8.3223e-01, -1.4136e-01, -8.9118e-01, -1.9858e+00, -4.2562e-01,\n",
      "         3.3684e-02,  8.2110e-01,  1.4019e+00,  6.7574e-02,  3.9490e-01,\n",
      "        -6.1005e-01,  1.4228e+00,  6.4380e-01,  4.4596e-01, -6.8921e-01,\n",
      "         3.2237e+00,  9.0785e-01, -3.6662e-01,  4.7890e-01,  3.2956e-01,\n",
      "         3.3298e-01,  8.4169e-01,  1.3068e+00,  8.2378e-01, -1.1558e-01,\n",
      "         7.3223e-01,  6.8738e-01,  9.5993e-02, -5.3454e-01, -7.4187e-01,\n",
      "         8.4298e-01,  8.5829e-01, -2.2049e-01,  2.8477e-01, -2.1522e-01])\n",
      "Glove vector:  tensor([ 1.6963e-01,  2.0912e-05,  5.1110e-01, -5.0768e-01,  6.9489e-01,\n",
      "        -1.1762e-01, -3.2955e-01,  5.3581e-01, -3.4780e-01,  2.9399e-01,\n",
      "        -4.4349e-01, -7.2387e-01, -5.8002e-01,  5.9233e-01,  8.1141e-01,\n",
      "        -8.3223e-01, -1.4136e-01, -8.9118e-01, -1.9858e+00, -4.2562e-01,\n",
      "         3.3684e-02,  8.2110e-01,  1.4019e+00,  6.7574e-02,  3.9490e-01,\n",
      "        -6.1005e-01,  1.4228e+00,  6.4380e-01,  4.4596e-01, -6.8921e-01,\n",
      "         3.2237e+00,  9.0785e-01, -3.6662e-01,  4.7890e-01,  3.2956e-01,\n",
      "         3.3298e-01,  8.4169e-01,  1.3068e+00,  8.2378e-01, -1.1558e-01,\n",
      "         7.3223e-01,  6.8738e-01,  9.5993e-02, -5.3454e-01, -7.4187e-01,\n",
      "         8.4298e-01,  8.5829e-01, -2.2049e-01,  2.8477e-01, -2.1522e-01])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imdb_vecs = glove_vecs.get_vecs_by_tokens(imdb_vocab.get_itos())\n",
    "for tok in [\"all\", \"hadn\", \"minutes\"]:\n",
    "    imdb_idx = imdb_vocab.get_stoi()[tok]\n",
    "    imdb_vec = imdb_vecs[imdb_idx]\n",
    "    \n",
    "    glove_idx = glove_vecs.stoi.get(tok, -1)\n",
    "    glove_vec = glove_vecs.vectors[glove_idx] if glove_idx >= 0 else None\n",
    "    \n",
    "    print(f\"Token: {tok}\")\n",
    "    print(f\"IMDB index: {imdb_idx}  Glove index: {glove_idx}\")\n",
    "    print(\"IMDB vector: \", imdb_vec)\n",
    "    print(\"Glove vector: \", glove_vec)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a343b6d1-5ba9-47c2-a375-8f0622cef2ef",
   "metadata": {},
   "source": [
    "Now I can just pass these vectors to the embedding table and have a valid vector for any token - whether or not it is found in Glove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "375a97fe-845c-4985-9b14-193dd93ec8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_emb = t.nn.Embedding.from_pretrained(imdb_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "566f3b61-c81f-4749-a37c-06331da47438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1925,  0.1001,  0.0638, -0.0877,  0.5222,  0.3911, -0.4198, -0.4567,\n",
       "         -0.3405, -0.1117,  0.0148,  0.3173, -0.5085, -0.1156,  0.7430,  0.0976,\n",
       "          0.3441, -0.1213, -0.1694, -0.8409, -0.1123,  0.4060,  0.7680,  0.0911,\n",
       "          0.1078, -1.2673, -0.5771, -0.3621,  0.3482, -0.7546,  4.0426,  0.9497,\n",
       "         -0.2267, -0.3578,  0.3413,  0.1307,  0.2305, -0.0370, -0.2589,  0.1298,\n",
       "         -0.3903, -0.0496,  0.4577,  0.5678, -0.4617,  0.4193, -0.5492,  0.0812,\n",
       "         -0.3049, -0.3051],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_stoi = imdb_vocab.get_stoi()\n",
    "x = t.tensor([imdb_stoi[\"all\"], imdb_stoi[\"hadn\"]])\n",
    "imdb_emb(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19c64e-3e44-4501-8289-500bb86d94b3",
   "metadata": {},
   "source": [
    "Embedding layer created from pre-trained vectors is frozen by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42d9aebc-2196-4153-98ab-01aaca4cf68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "for param in imdb_emb.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1e24b-4add-4917-9996-df7a5ebf7e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
