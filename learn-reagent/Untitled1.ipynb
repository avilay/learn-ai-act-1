{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eded8d47-2f08-4e56-a61f-78b3fc3fe0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "import pytorch_lightning as pl\n",
    "import logging\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04817d73-2b4e-442c-beda-0e113364d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"reagent\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ba44498-73a8-492d-bf15-457ca3aa5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reagent.gym.envs import Gym\n",
    "from reagent.core.parameters import RLParameters\n",
    "from reagent.optimizer.uninferrable_optimizers import Adam\n",
    "from reagent.optimizer.union import Optimizer__Union\n",
    "from reagent.training import DQNTrainerParameters\n",
    "from reagent.net_builder.unions import DiscreteDQNNetBuilder__Union\n",
    "from reagent.net_builder.discrete_dqn.fully_connected import FullyConnected\n",
    "from reagent.model_managers.discrete.discrete_dqn import DiscreteDQN\n",
    "from reagent.gym.utils import build_normalizer, fill_replay_buffer\n",
    "from reagent.replay_memory.circular_replay_buffer import ReplayBuffer\n",
    "from reagent.gym.policies.random_policies import make_random_policy_for_env\n",
    "from reagent.gym.agents.agent import Agent\n",
    "from reagent.gym.datasets.replay_buffer_dataset import ReplayBufferDataset\n",
    "from reagent.gym.runners.gymrunner import evaluate_for_n_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2b89ed-b705-4fba-ac3e-49f19868e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Gym(env_name=\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17fdd16a-2917-4341-bb68-09e78ca1cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_params = RLParameters(\n",
    "    gamma=0.99, \n",
    "    epsilon=0.1, \n",
    "    target_update_rate=0.2, \n",
    "    maxq_learning=True, \n",
    "    reward_boost=None, \n",
    "    temperature=1.0, \n",
    "    softmax_policy=False, \n",
    "    use_seq_num_diff_as_time_diff=False, \n",
    "    q_network_loss='mse', \n",
    "    set_missing_value_to_zero=False, \n",
    "    tensorboard_logging_freq=0, \n",
    "    predictor_atol_check=0.0, \n",
    "    predictor_rtol_check=5e-05, \n",
    "    time_diff_unit_length=1.0, \n",
    "    multi_steps=None, \n",
    "    ratio_different_predictions_tolerance=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4942d10-ee8a-43e4-a42a-c121a701972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(\n",
    "    lr_schedulers=[], \n",
    "    lr=0.05, \n",
    "    betas=(0.9, 0.999), \n",
    "    eps=1e-08, \n",
    "    weight_decay=0.0, \n",
    "    amsgrad=False\n",
    ")\n",
    "optim = Optimizer__Union(Adam=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d3a3897-d246-4cc5-b9e0-f0543c355161",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_params = DQNTrainerParameters(\n",
    "    actions=[\"0\", \"1\"],\n",
    "    rl=rl_params,\n",
    "    double_q_learning=True,\n",
    "    bcq=None,\n",
    "    minibatch_size=1024,\n",
    "    minibatches_per_step=1,\n",
    "    optimizer=optim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0472f2bb-3ae9-41c9-b9d5-6fa86afaefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_builder = DiscreteDQNNetBuilder__Union(\n",
    "    Dueling=None, \n",
    "    FullyConnected=FullyConnected(\n",
    "        sizes=[128, 64],\n",
    "        activations=[\"leaky_relu\", \"leaky_relu\"],\n",
    "        dropout_ratio=0.0,\n",
    "        use_batch_norm=False\n",
    "    ),\n",
    "    FullyConnectedWithEmbedding=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ffe8043-da97-492d-9dac-eec6f208889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpe_net_builder = DiscreteDQNNetBuilder__Union(\n",
    "    Dueling=None,\n",
    "    FullyConnected=FullyConnected(\n",
    "        sizes=[256, 128],\n",
    "        activations=[\"relu\", \"relu\"],\n",
    "        dropout_ratio=0.0,\n",
    "        use_batch_norm=False\n",
    "    ),\n",
    "    FullyConnectedWithEmbedding=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "160b909b-bb64-442d-b5f3-efe5124920b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DiscreteDQN(\n",
    "    trainer_param=trainer_params,\n",
    "    net_builder=net_builder,\n",
    "    cpe_net_builder=cpe_net_builder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36b4d564-6b98-4d35-913c-0c159f1cf538",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory_size = 100000\n",
    "train_every_ts = 1\n",
    "train_after_ts = 20000\n",
    "num_train_episodes = 30\n",
    "passing_score_bar = 100.0\n",
    "num_eval_episodes = 20\n",
    "use_gpu = False\n",
    "minibatch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cb48272-7838-4811-bc2e-584665fd18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = build_normalizer(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f9ad74a-11e1-46cf-9e41-28ec92fb9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = dqn.build_trainer(\n",
    "    use_gpu=False, \n",
    "    normalization_data_map=normalization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61ce0dbd-2462-49ba-9a23-1b031a798d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_policy = dqn.create_policy(trainer, serving=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c29f679-ba19-4af6-9b8b-66e20f7fe2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(\n",
    "    replay_capacity=replay_memory_size, batch_size=minibatch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c8ad7c8-dad7-46cc-b41f-98f37b9254c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = t.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03d4c221-48ce-4995-a15a-7ebe0da33276",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = make_random_policy_for_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6dfacd2-c3ec-4413-99e8-9a00025b568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent.create_for_env(env, policy=random_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47c795ab-fa5d-47a1-bd91-f4239a8455ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling replay buffer from 0 to size 20000: 100%|██████████| 20000/20000 [00:09<00:00, 2037.28it/s]\n"
     ]
    }
   ],
   "source": [
    "fill_replay_buffer(\n",
    "    env=env, \n",
    "    replay_buffer=replay_buffer, \n",
    "    desired_size=train_after_ts, \n",
    "    agent=agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc0f50ec-cf28-4349-b4d5-a6fbe50fda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent.create_for_env(\n",
    "    env, \n",
    "    policy=training_policy, \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93b4ee72-0d95-4c42-9f6f-f7934f60c02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reagent.gym.preprocessors.trainer_preprocessor:Deriving trainer_preprocessor from OrderedDict([('training_batch', <Parameter \"training_batch: reagent.core.types.DiscreteDqnInput\">), ('batch_idx', <Parameter \"batch_idx: int\">)])\n"
     ]
    }
   ],
   "source": [
    "dataset = ReplayBufferDataset.create_for_trainer(\n",
    "    trainer,\n",
    "    env,\n",
    "    agent,\n",
    "    replay_buffer,\n",
    "    batch_size=minibatch_size,\n",
    "    training_frequency=train_every_ts,\n",
    "    num_episodes=num_train_episodes,\n",
    "    max_steps=200,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08f11e1a-ded1-4cef-a401-170a72b8fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = t.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    collate_fn=lambda batch: batch[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f342ac4-2612-4142-adc8-e666b25e9b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "pl_trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    gpus=int(use_gpu),\n",
    "    deterministic=True,\n",
    "    default_root_dir=f\"lightning_log_{str(uuid.uuid4())}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02366097-9d4b-42c5-ac50-385e1bbda646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avilay/projects/cloned/pytorch-lightning/pytorch_lightning/trainer/configuration_validator.py:102: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  rank_zero_warn(f'you defined a {step_name} but have no {loader_name}. Skipping {stage} loop')\n",
      "\n",
      "  | Name                 | Type              | Params\n",
      "-----------------------------------------------------------\n",
      "0 | q_network            | FullyConnectedDQN | 9.0 K \n",
      "1 | q_network_target     | FullyConnectedDQN | 9.0 K \n",
      "2 | reward_network       | FullyConnectedDQN | 34.4 K\n",
      "3 | q_network_cpe        | FullyConnectedDQN | 34.4 K\n",
      "4 | q_network_cpe_target | FullyConnectedDQN | 34.4 K\n",
      "-----------------------------------------------------------\n",
      "121 K     Trainable params\n",
      "0         Non-trainable params\n",
      "121 K     Total params\n",
      "0.485     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avilay/projects/cloned/pytorch-lightning/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87ad137d1254c1d95c7968d71ed8c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training episode: 1, total episode reward = 18.0\n",
      "\n",
      "Training episode: 2, total episode reward = 9.0\n",
      "\n",
      "Training episode: 3, total episode reward = 10.0\n",
      "\n",
      "Training episode: 4, total episode reward = 102.0\n",
      "\n",
      "Training episode: 5, total episode reward = 200.0\n",
      "\n",
      "Training episode: 6, total episode reward = 200.0\n",
      "\n",
      "Training episode: 7, total episode reward = 104.0\n",
      "\n",
      "Training episode: 8, total episode reward = 145.0\n",
      "\n",
      "Training episode: 9, total episode reward = 108.0\n",
      "\n",
      "Training episode: 10, total episode reward = 132.0\n",
      "\n",
      "Training episode: 11, total episode reward = 94.0\n",
      "\n",
      "Training episode: 12, total episode reward = 98.0\n",
      "\n",
      "Training episode: 13, total episode reward = 79.0\n",
      "\n",
      "Training episode: 14, total episode reward = 82.0\n",
      "\n",
      "Training episode: 15, total episode reward = 85.0\n",
      "\n",
      "Training episode: 16, total episode reward = 94.0\n",
      "\n",
      "Training episode: 17, total episode reward = 200.0\n",
      "\n",
      "Training episode: 18, total episode reward = 200.0\n",
      "\n",
      "Training episode: 19, total episode reward = 200.0\n",
      "\n",
      "Training episode: 20, total episode reward = 153.0\n",
      "\n",
      "Training episode: 21, total episode reward = 112.0\n",
      "\n",
      "Training episode: 22, total episode reward = 85.0\n",
      "\n",
      "Training episode: 23, total episode reward = 87.0\n",
      "\n",
      "Training episode: 24, total episode reward = 101.0\n",
      "\n",
      "Training episode: 25, total episode reward = 200.0\n",
      "\n",
      "Training episode: 26, total episode reward = 200.0\n",
      "\n",
      "Training episode: 27, total episode reward = 200.0\n",
      "\n",
      "Training episode: 28, total episode reward = 200.0\n",
      "\n",
      "Training episode: 29, total episode reward = 200.0\n",
      "\n",
      "Training episode: 30, total episode reward = 200.0\n",
      "Episode rewards during training:\n",
      "[18.0, 9.0, 10.0, 102.0, 200.0, 200.0, 104.0, 145.0, 108.0, 132.0, 94.0, 98.0, 79.0, 82.0, 85.0, 94.0, 200.0, 200.0, 200.0, 153.0, 112.0, 85.0, 87.0, 101.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]\n"
     ]
    }
   ],
   "source": [
    "pl_trainer.fit(trainer, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1de4136d-d65e-4997-a508-a1f169246f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avilay/projects/cloned/ReAgent/reagent/preprocessing/preprocessor.py:120: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input.shape == input_presence_byte.shape\n"
     ]
    }
   ],
   "source": [
    "serving_policy = dqn.create_policy(\n",
    "    trainer, \n",
    "    serving=True, \n",
    "    normalization_data_map=normalization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5e53a32-0ed1-4037-b2df-5b9bbe17f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent.create_for_env_with_serving_policy(env, serving_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ceb2c597-f13d-44d2-b62e-f5857fb58b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rewards = evaluate_for_n_episodes(\n",
    "    n=num_eval_episodes,\n",
    "    env=env,\n",
    "    agent=agent,\n",
    "    max_steps=env.max_steps,\n",
    "    num_processes=1,\n",
    ").squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05b045f3-1d90-4564-a311-fd3c9e1b6e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(eval_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29efe834-e806-4bb1-9021-33de646628f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200., 200., 200., 200., 200., 200., 200., 200., 200., 200., 200.,\n",
       "       200., 200., 200., 200., 200., 200., 200., 200., 200.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d36cc-022a-4a29-80b7-062c16de8107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
