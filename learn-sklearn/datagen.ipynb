{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as skdata\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `make_classification` parameters\n",
    "This is a very useful function so it is good to internalize its parameters. In the code cells below, the commented value is the default value. At the core of this method is the generation of an n-dimensional hypercube. Don't get too worried about this. A 2-dimensional hypercube is just a square, i.e., we choose 4 equidistant points on a 2-D plane -\n",
    "\n",
    "| $x_1$ | $x_2$ |\n",
    "|-------|-------|\n",
    "| -2    | -2    |\n",
    "| 2     | -2    |\n",
    "| 2     | 2     |\n",
    "| -2    | 2     |\n",
    "\n",
    "Similarly an n-dimensional hypercube will just be equidistant points in an n-dimensional space. Nothing too complicated.\n",
    "\n",
    "So this function generates an n-dimensional hypercube, where $n$ is the number of features. Then for each class it will create Gaussian clusters centered at each vertex. Then it will sample points from each cluster. It will further combine the selected points within each cluster for some reason. Each point will be n-dimensional, thus giving us a full sample. Imagine this in 2D and it will become a lot clearer.\n",
    "\n",
    "![hypercube](./imgs/hypercubes2.png)\n",
    "\n",
    "In the picture above, there are 2 features and 2 classes - blue and orange. A 2D hypercube is generated, gaussian clusters created at their vertices, and points sampled from these clusters give us the blue and orange samples. \n",
    "\n",
    "<span style=\"color:red\">IMPORTANT: It is not clear from the documentation whether or not a vertex can host clusters of different classes. It seems likely that it does not.</span> This is because there cannot be more clusters than the number of vertices, i.e., $ck \\leqslant 2^n$ where $c$ is the number of classes, $k$ is the number of clusters per class, so $ck$ is the total number of clusters, and $n$ is the number of features.\n",
    "\n",
    "In the cells below, the commented value is the default."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypercubes\n",
    "There are a number of parameters that control the hypercube. First of all the `hypercube` parameter determines whether this hypercube scheme is used at all or not. I can set the length of the hypercube with `class_sep`. Higher values means that the classes are easy to discriminate and therefore the classification task is easier. \n",
    "\n",
    "<span style=\"color:red\">The following is just a hunch</span>\n",
    "I can also somewhat control where in the n-dimensional space the vertices of the hypercube will lie, e.g., in the example above, I can somewhat control whether the vertices are (2, 2), (2, -2), (-2, 2), and (-2, -2) or some other points. This is done by the `shift` parameter, where sklearn will shift the points after they have been chosen (randomly?). If I specify `None`, then the points are shifted by some value chosen randomly from $[-l, l]$ where $l$ is the length of the hypercube. So far I have not found a good explanation of this on the Internet and I am too lazy to look up the source code.\n",
    "\n",
    "Another useful parameter is `scale` which will scale the points by whatever I specify. If this is `None`, then the points are scaled by some value drawn randomly between $[1, 100]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypercube = True\n",
    "hypercube = True\n",
    "\n",
    "# class_sep = 1.0\n",
    "class_sep = 0.8\n",
    "\n",
    "# shift = 0.0\n",
    "shift = 0.0\n",
    "\n",
    "# scale = 1.0\n",
    "scale = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes\n",
    "When creating the clusters centered on the hypercube vertices, sklearn does not always create 1 cluster per vertex. I can specify how many clusters to create per class. Further I can specify the proportion of samples for each class. If I don't specify anything, the dataset will be more-or-less balanced. In order to generate noise, I can specify the `flip_y` parameter which is the fraction of samples whose class will be assigned randomly. Obviously, the higher this value, the harder the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_classes = 2\n",
    "n_classes = 3\n",
    "\n",
    "# n_clusters_per_class = 2\n",
    "n_clusters_per_class = 2\n",
    "\n",
    "# weights = None\n",
    "weights = [0.1, 0.2, 0.7]\n",
    "\n",
    "# flip_y = 0.01\n",
    "flip_y = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples\n",
    "The total number of samples to generate using the `n_samples` parameter. Pretty strightforward. I can also choose whether to shuffle the samples and the features. Without shuffling the features are in order of informative, redundant, repeated, and useless. The `random_state` sets the random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples = 100\n",
    "n_samples = 100\n",
    "\n",
    "# shuffle = True\n",
    "shuffle = False\n",
    "\n",
    "# random_state = None\n",
    "random_state = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Features\n",
    "The main parameter is the `n_informative`, this is the \"real\" number of features, the hypercubes are based on this. Additionally I can inject a bunch of redundant features which are just random linear combination of the informative features, repeated features that are duplicated from the informative and redundant features. Finally there can be a number of useless features that are completely random. There is no way to specify the number of useless features, but it is calculated from the total number of features.\n",
    "```\n",
    "n_features = n_informative + n_redundant + n_repeated + n_useless\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features = 20\n",
    "n_features = 7\n",
    "\n",
    "# n_informative = 2\n",
    "n_informative = 3\n",
    "\n",
    "# n_redundant = 2\n",
    "n_redundant = 2\n",
    "\n",
    "# n_repeated = 0\n",
    "n_repeated = 1\n",
    "\n",
    "# n_useless is 7 - 3 - 2 - 1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = skdata.make_classification(\n",
    "    # hypercube\n",
    "    hypercube=hypercube,\n",
    "    class_sep=class_sep,\n",
    "    shift=shift,\n",
    "    scale=scale,\n",
    "    \n",
    "    # classes\n",
    "    n_classes=n_classes,\n",
    "    n_clusters_per_class=n_clusters_per_class,\n",
    "    weights=weights,\n",
    "    flip_y=flip_y,\n",
    "    \n",
    "    # samples\n",
    "    n_samples=n_samples,\n",
    "    shuffle=shuffle,\n",
    "    random_state=random_state,\n",
    "\n",
    "    # features\n",
    "    n_features=n_features,\n",
    "    n_informative=n_informative,\n",
    "    n_redundant=n_redundant,\n",
    "    n_repeated=n_repeated,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 7) (100,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c957e4ca480fc31da01b2648e097b4e55db834b6351128636991f182c884d81e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
