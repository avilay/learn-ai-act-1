{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.data as tfd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating datasets from Sequence\n",
    "In general I am quite sick of the `tf.data.Dataset` object. It's mappers work only on tensor graphs, even for eager execution. This makes the entire API set pretty non-intuitive. An alternative is to build my own pipeline and wrap it inside the `tf.keras.utils.Sequence` object.\n",
    "\n",
    "The `__getitem__` method should return a batch. Keras will take care of shuffling the batches, so that `batch[n+1]` will not always follow `batch[n]`, but my code will have to take care of shuffling within the batch, so that `batch[m]` in one epoch is not exactly same as `batch[m]` in another epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self):\n",
    "        self.w = np.array([1., 2., 3.])\n",
    "        self.b = 0.5\n",
    "        self._num_batches = 100\n",
    "        self._batch_size = 8\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._num_batches\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = np.random.random((self._batch_size, 3))\n",
    "        y = (x@self.w) + self.b\n",
    "        d = np.random.standard_normal(self._batch_size)\n",
    "        return x, y+d\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use this in a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = layers.Input(shape=(3,))\n",
    "y_hat = layers.Dense(1)(x)\n",
    "model = keras.Model(x, y_hat)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2935 - mae: 0.8889\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0665 - mae: 0.8286\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1966 - mae: 0.8768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x130f78c18>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(MyDataset(), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating datasets with Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given, I don't like `Dataset`, why bother with it all? There are a bunch of ready-made datasets offered by `tensorflow-datasets` package. These output the data as `Dataset` objects so it is useful to know how to use it.\n",
    "\n",
    "The `Dataset` object is the workhorse object of all data manipulations. This is an abstract base class and every data provider must implement their own `Dataset` subclass. However, there are a number of built-in static methods that can be used for soem generic scenarios. The two most common ones are to create a dataset from a numpy/tf tensor; and to create a dataset from a python generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets from tensors\n",
    "\n",
    "When given a simple array, each element of the array will form a single element. When given a matrix, each row will form a single element. It is also possible to give a tuple of tensors as input. In this case, each tuple will be sliced elementwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tfd.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most general way to accessing the dataset is to run it through a `for-loop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x in ds:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dataset implementations will also expose an iterator. The `TensorSliceDataset` does that. But not all datasets will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=30, shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(ds)\n",
    "x = next(it)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
      "1 tf.Tensor([4. 5. 6.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ds = tfd.Dataset.from_tensor_slices([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.]\n",
    "])\n",
    "for i, x in enumerate(ds):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (<tf.Tensor: id=51, shape=(1,), dtype=float64, numpy=array([10.])>, <tf.Tensor: id=52, shape=(3,), dtype=float64, numpy=array([1., 2., 3.])>)\n",
      "1 (<tf.Tensor: id=55, shape=(1,), dtype=float64, numpy=array([20.])>, <tf.Tensor: id=56, shape=(3,), dtype=float64, numpy=array([4., 5., 6.])>)\n"
     ]
    }
   ],
   "source": [
    "mat = tf.constant(np.array([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.]\n",
    "]))\n",
    "vec = tf.constant(np.array([\n",
    "    [10.],\n",
    "    [20.]\n",
    "]))\n",
    "ds = tfd.Dataset.from_tensor_slices((vec, mat))\n",
    "for i, x in enumerate(ds):\n",
    "    # x will be a two element tuple, with the first element from vec and the second from mat\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets from generators\n",
    "It is good practics to provide the `output_shapes` arg when creating datasets from generators. If a particular dimension is unknown or is variable, use `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(stop):\n",
    "    i = 0\n",
    "    while i < stop:\n",
    "        yield np.random.randint(10, 1000, (3, 2))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0815 17:25:05.838013 4577142208 deprecation.py:323] From /Users/avilay/venvs/ai/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "ds = tfd.Dataset.from_generator(count, args=[5], output_types=tf.int32, output_shapes=(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor(\n",
      "[[691 875]\n",
      " [688 677]\n",
      " [365 742]], shape=(3, 2), dtype=int32)\n",
      "1 tf.Tensor(\n",
      "[[706 518]\n",
      " [291 967]\n",
      " [177 168]], shape=(3, 2), dtype=int32)\n",
      "2 tf.Tensor(\n",
      "[[483 919]\n",
      " [299 290]\n",
      " [677 379]], shape=(3, 2), dtype=int32)\n",
      "3 tf.Tensor(\n",
      "[[644 994]\n",
      " [278 486]\n",
      " [673 152]], shape=(3, 2), dtype=int32)\n",
      "4 tf.Tensor(\n",
      "[[178  29]\n",
      " [823 978]\n",
      " [249 164]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(ds):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rnd(stop):\n",
    "    i = 0\n",
    "    while i < stop:\n",
    "        nrows = np.random.randint(2, 5)\n",
    "        yield np.random.random((nrows, 3))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfd.Dataset.from_generator(count_rnd, args=[3], output_types=tf.float32, output_shapes=(None, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor(\n",
      "[[0.38219634 0.40371072 0.7774332 ]\n",
      " [0.98708916 0.30993912 0.00245317]], shape=(2, 3), dtype=float32)\n",
      "1 tf.Tensor(\n",
      "[[0.57388437 0.89134675 0.44393557]\n",
      " [0.80804914 0.1617799  0.8996212 ]], shape=(2, 3), dtype=float32)\n",
      "2 tf.Tensor(\n",
      "[[0.18673097 0.5564268  0.08767605]\n",
      " [0.65918577 0.31532907 0.04343607]\n",
      " [0.7139551  0.42873502 0.7228817 ]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(ds):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zipping arbitrary datasets\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pipelines\n",
    "\n",
    "`Dataset` object has a bunch of Spark like methods to process data, e.g., `map`. The weird thing about `map` is that it internally converts eager tensors into graph tensors. This means that I cannot call `x.numpy()` for example. In the example below see that the type of the tensor inside the mapper is `tensorflow.python.framework.ops.Tensor` not to be confused with `tf.Tensor`. And inside the for loop the tensors are avialable again as eager tensors `tensorflow.python.framework.ops.EagerTensor`.\n",
    "\n",
    "`map` can be parallelized. For the most part I can use the `tf.data.experimental.AUTOTUNE` constant to let tf dynamically scale with the number of avialable CPUs. This is very useful when reading data from disk or network. See example of this in the image processing example.\n",
    "\n",
    "Another useful method is `take(n)` which works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "def gen_vec(count=5):\n",
    "    for _ in range(count):\n",
    "        yield tf.random.uniform((3,))\n",
    "\n",
    "def mapper(x):\n",
    "    print(type(x))\n",
    "    return x\n",
    "    \n",
    "    \n",
    "for x in tfd.Dataset.from_generator(gen_vec, output_types=tf.float32).map(mapper):\n",
    "    print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.36576295 0.7977334  0.35978234], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0.77115643 0.8696778  0.64151216], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x in tfd.Dataset.from_generator(gen_vec, output_types=tf.float32).take(2):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching and Shuffling\n",
    "Typically I want to shuffle the input dataset for each epoch and I want to access it in batches. `Dataset` supports both these use cases. It also has a `prefetch` method which will prefetch the next batch while the current batch is being processed. See use in processing images example.\n",
    "\n",
    "`shuffle()` will work \"best\", i.e., with maximum randomization if the shuffle size is at least as big as the dataset size. Of course if the full dataset size does not fit in memory, use the biggest possible. Conceptually here is what happens. Lets say I specify shuffle size of 100. Then tf will create a queue of size 100 and fill it with elements from the dataset, lets say items with index 0 to 99. With the first iteration it will randomly pick an item from the queue, i.e., any item from 0 to 99, lets say item number 50. Then it will add item 100 to the queue. In the next iteration it will randomly select from this queue and add item 101 to the queue and so on.\n",
    "\n",
    "It is important to call `shuffle()` before `batch()`. Otherwise it will shuffle the batches, but not items within the batch. In other words, each queue element will be a full batch, not individual instances from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter():\n",
    "    i = 0\n",
    "    while i < 500:\n",
    "        yield i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n",
      "tf.Tensor(2, shape=(), dtype=int8)\n",
      "tf.Tensor(3, shape=(), dtype=int8)\n",
      "tf.Tensor(4, shape=(), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "ds = tfd.Dataset.from_generator(counter, output_types=tf.int8)\n",
    "for x in ds.take(5):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `shuffle` being called, each element is out of order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int8)\n",
      "tf.Tensor(7, shape=(), dtype=int8)\n",
      "tf.Tensor(9, shape=(), dtype=int8)\n",
      "tf.Tensor(6, shape=(), dtype=int8)\n",
      "tf.Tensor(12, shape=(), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "for x in ds.shuffle(16).take(5):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When batching, each element is a batch of the specified size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6 7], shape=(8,), dtype=int8)\n",
      "tf.Tensor([ 8  9 10 11 12 13 14 15], shape=(8,), dtype=int8)\n",
      "tf.Tensor([16 17 18 19 20 21 22 23], shape=(8,), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "for x in ds.batch(8).take(3):\n",
    "    # Each x will be 8 elements long\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling `shuffle` before `batch`, each batch is shuffled. The elements in each batch are out of order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([12  0 13  7  9 20  1 18], shape=(8,), dtype=int8)\n",
      "tf.Tensor([ 4 24  6 10 11 21  8 19], shape=(8,), dtype=int8)\n",
      "tf.Tensor([17 26 27 29 22 30 25 31], shape=(8,), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "for x in ds.shuffle(16).batch(8).take(3):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling `shuffle` after `batch`, while the batches are out of order, internally each batch is in-order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([24 25 26 27 28 29 30 31], shape=(8,), dtype=int8)\n",
      "tf.Tensor([88 89 90 91 92 93 94 95], shape=(8,), dtype=int8)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7], shape=(8,), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "for x in ds.batch(8).shuffle(16).take(3):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Sizes\n",
    "With a dataset the size of 500 elements, I expect to see 500/8 = 62.5 batches of size 8, i.e., I'll see 63 batches, with the last batch having 4 elements. To have uniform batch sizes I can drop the last batch. The last batch will only be dropped if it has less number of elements. Otherwise I'll get all the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = []\n",
    "for x in ds.batch(8):\n",
    "    batch_sizes.append(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 4 "
     ]
    }
   ],
   "source": [
    "print(len(batch_sizes))\n",
    "for batch_size in batch_sizes:\n",
    "    print(batch_size, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = []\n",
    "for x in ds.batch(8, drop_remainder=True):\n",
    "    batch_sizes.append(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 "
     ]
    }
   ],
   "source": [
    "print(len(batch_sizes))\n",
    "for batch_size in batch_sizes:\n",
    "    print(batch_size, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = []\n",
    "for x in ds.batch(10, drop_remainder=True):\n",
    "    batch_sizes.append(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating\n",
    "Typically `keras` built-in models have a single method `fit` which will take in a dataset that yields a tuple of (X, y), the number of epochs to train for, and the number of \"steps\" per epoch. In such cases I want the dataset to loop endlessly and let `keras` take care of iterating the correct number of times. The number of steps here would typically be the number of batches. In psedocode, insteading of saying -\n",
    "```\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataset:\n",
    "        model.train(batch)\n",
    "```\n",
    "I say the following:\n",
    "```\n",
    "model.train(dataset, epochs=num_epochs, steps_per_epoch=num_batches)\n",
    "```\n",
    "\n",
    "Again, it is important to call `shuffle` before `repeat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfd.Dataset.from_generator(gen_vec, output_types=tf.int8)\n",
    "ds = ds.shuffle(16)\n",
    "ds = ds.repeat()  # --> Important to call after shuffle\n",
    "ds = ds.batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
