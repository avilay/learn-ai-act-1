{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "import numpy as np\n",
    "from imdb.imdb_reviews import ImdbReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = path.expanduser(\"~/mldata/imdb-reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [00:28<00:00, 1381.86it/s]\n"
     ]
    }
   ],
   "source": [
    "imdb_train = ImdbReviews(dataroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imdb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([40000, 250])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train._encoded_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([40000, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train._targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = imdb_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_batch[0]\n",
    "y = y_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(250,), dtype=int32, numpy=\n",
       "array([70250, 33996, 80935, 61359, 79231, 17293, 27466, 46996, 34619,\n",
       "       22602,  6740, 24905, 45344, 86548, 23421, 19207, 20005, 41857,\n",
       "       19019, 45344, 45677, 70250, 36330, 57129, 70250, 45624, 54547,\n",
       "       83303, 32491, 10786, 46996, 20300, 84837, 63962, 84837, 54547,\n",
       "        1893,  7907, 35602,  9638, 46996, 33996, 70975, 78291, 84837,\n",
       "       63962,  6740, 50229, 84837, 14272, 91648, 81956, 33996,  1515,\n",
       "       43191, 33996, 15574, 80984, 46996, 78803, 79747, 32253, 70250,\n",
       "       33996, 33819, 45624, 33996, 24574,  9137, 33996, 34077, 59044,\n",
       "       45703, 67968,  9137, 76738, 13468, 88421, 13468, 33996, 44164,\n",
       "       27444, 26351, 81956, 33996, 41286, 82273, 43191, 54547, 86305,\n",
       "       79231, 45344, 69074,  8744, 10446, 63900, 81956, 45703, 54547,\n",
       "       65679, 33996, 19140, 70250, 79231, 61359, 65677, 54345, 12529,\n",
       "       15197,  8621,  9137, 19855, 36330, 54547, 83303, 27697, 45554,\n",
       "       86548, 51817, 20300, 84837, 46114, 84837, 39198, 70250, 33996,\n",
       "       54717, 74614, 19893, 53833, 50187, 41828, 15197, 54547, 83970,\n",
       "       13468, 76691, 53824, 82738, 33996, 20822, 70192, 61359, 54547,\n",
       "       49325, 45344, 45677, 70250, 38903, 10470, 57736, 53833, 84837,\n",
       "       73196, 33996, 88367, 27967, 53824, 46996, 20300, 45703, 89178,\n",
       "       14272, 38400, 15938, 23421, 53833, 45703, 86204, 14844, 88367,\n",
       "       45057, 13468, 33835, 84855, 33996, 78291, 10740, 54547, 83303,\n",
       "       14254, 26455, 81956, 19207, 78807, 28660, 33996, 86548, 84964,\n",
       "       13468, 66046, 27588, 65704, 33996, 57129, 70192, 54547, 46996,\n",
       "       84837, 70250, 44798,  6551, 46797, 46996, 13468, 53824, 33996,\n",
       "        3767, 27967, 26351, 18762, 66726, 52797,  7907, 33996, 23927,\n",
       "        4725, 33996, 23927, 25052, 82722, 61359, 50971, 45624, 33996,\n",
       "       74668, 37542, 49428, 19207, 46996, 20300, 46797, 26351, 15197,\n",
       "       54547, 83303, 85571, 27967, 34619, 54547, 46996, 85571,  2880,\n",
       "       13468,  7948, 20407, 70192, 14844, 45344, 31429], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of the puzzle and sometimes saying aha is what makes or breaks a show like this one surface had a couple of flaws first of all it s basic premise is not as exciting as it could have been nor is the revealed story as exciting or daring as i hoped in the beginning also the tv feeling is very present much of the time all the way from the crappy cgi that ranges from decent to awful to the rather shifting quality in the acting department also it feels sometimes a bit too family oriented in that it takes the edge of sometimes and becomes almost cutesy but aside from these flaws it s an enjoyable show maybe not as spectacular as some of the other sci fi shows out there but it manages to keep me interested the whole season and it offers a couple of nice cliffhangers between shows as well the ending for me is not that appealing i don t like shows that end without ending so to speak leaving the story unresolved it s especially unfortunate in this case since the show seems to be canceled after the first season it is as of yet undecided hbo is to me the benchmark for quality television their series have the best actors the best production values and above all the most solid writing this is not hbo quality but it s good for what it is good enough to want another season without a doubt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.encoder.decode(x[x>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.label(y.numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = path.expanduser(\"~/mldata/glove/glove_6b_100d.pkl\")\n",
    "with open(glove_embeddings, \"rb\") as f:\n",
    "    embeddings_ndx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_ndx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.086, -0.222,  0.166,  0.134,  0.382,  0.354,  0.013,  0.225,\n",
       "       -0.438,  0.502, -0.359, -0.35 ,  0.055,  0.696, -0.18 ,  0.068,\n",
       "        0.391,  0.16 , -0.266, -0.211,  0.537,  0.494,  0.937,  0.669,\n",
       "        0.218, -0.466,  0.224, -0.362, -0.177,  0.175, -0.204,  0.139,\n",
       "        0.02 , -0.104, -0.202,  0.55 , -0.155,  0.987, -0.269, -0.291,\n",
       "       -0.329, -0.342, -0.169, -0.42 , -0.047, -0.163,  0.708, -0.749,\n",
       "       -0.092, -0.962, -0.197,  0.103,  0.552,  1.382, -0.656, -3.25 ,\n",
       "       -0.316, -1.206,  1.771,  0.403, -0.798,  1.16 , -0.33 ,  0.314,\n",
       "        0.774,  0.226,  0.525, -0.034,  0.32 ,  0.08 ,  0.178, -0.494,\n",
       "       -0.7  , -0.446,  0.172,  0.203,  0.023, -0.207, -1.016,  0.183,\n",
       "        0.568,  0.318, -0.65 ,  0.683, -0.866, -0.059, -0.293, -0.557,\n",
       "       -0.347, -0.329,  0.402, -0.127, -0.202,  0.874, -0.545,  0.792,\n",
       "       -0.207, -0.074,  0.758, -0.342], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embeddings_ndx[\"in\"].shape)\n",
    "embeddings_ndx[\"in\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94923"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(imdb_train.encoder.tokens)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros((vocab_size+1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(imdb_train.encoder.tokens):\n",
    "    idx = i + 1\n",
    "    if token in embeddings_ndx:\n",
    "        embeddings[idx] = embeddings_ndx[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anda'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.encoder.tokens[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.231, -0.524, -0.034,  0.287,  0.296, -0.305, -0.271,  0.444,\n",
       "        0.744,  0.346, -0.236,  1.017, -1.25 ,  0.01 ,  0.251,  0.217,\n",
       "        0.161, -0.02 , -0.225, -0.028,  0.169,  0.334, -0.328,  0.78 ,\n",
       "       -0.545, -0.029, -0.171, -0.019, -0.245, -0.617, -0.513, -0.106,\n",
       "       -0.37 ,  0.085,  0.506,  0.142,  0.835,  0.265, -0.153,  0.183,\n",
       "        0.55 , -0.061, -0.724,  0.562, -0.7  , -0.277, -0.349,  0.068,\n",
       "       -0.697,  0.403, -0.107, -0.75 ,  0.272, -0.809, -0.589,  0.292,\n",
       "        0.4  ,  0.439, -0.836,  0.233,  0.578, -0.545, -0.121,  0.211,\n",
       "        0.237, -0.211, -0.436,  0.407, -0.399,  0.366, -0.09 , -0.238,\n",
       "        0.118, -0.899,  0.25 ,  0.258,  0.638, -0.08 , -0.28 , -0.095,\n",
       "        0.13 , -1.236, -0.235, -0.264,  0.311,  0.278, -0.258,  0.334,\n",
       "       -0.406,  0.124,  0.591, -0.419,  0.026,  1.196,  0.066,  0.214,\n",
       "       -0.088, -0.188, -0.438, -0.222])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.891,  0.892, -0.563,  0.453,  0.027, -0.169,  0.35 , -0.007,\n",
       "        0.37 ,  0.051,  0.235,  0.682, -0.403,  0.503, -0.261,  0.463,\n",
       "        0.784, -0.232,  0.004,  0.515,  0.052, -0.472, -0.258,  0.123,\n",
       "       -0.576,  0.879,  0.096,  0.028,  0.331,  0.432,  0.144,  0.222,\n",
       "       -0.997, -0.552, -0.166,  0.032, -0.139,  0.147, -0.044, -0.24 ,\n",
       "       -0.325, -0.978, -0.61 , -0.603, -0.199,  0.203, -0.124, -0.093,\n",
       "       -0.155, -0.007, -0.304,  0.422,  0.379,  1.169, -0.002, -0.349,\n",
       "       -0.376, -0.911,  0.408, -0.494,  0.368,  0.148, -0.413, -0.401,\n",
       "        0.598, -0.882,  0.758, -0.238,  0.011, -1.046, -0.161,  0.325,\n",
       "        0.178,  0.07 ,  0.498,  0.489, -0.041, -0.921, -0.841,  0.381,\n",
       "        0.488,  0.105, -1.121,  0.546, -0.652, -0.009,  1.551,  0.712,\n",
       "        0.121,  0.693, -0.334, -0.053, -0.821, -0.266,  0.12 , -0.946,\n",
       "       -0.037, -0.469,  0.052,  0.095], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_ndx[\"extract\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "from haikunator import Haikunator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1, 100, input_length=imdb_train.max_seq_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embeddings])\n",
    "model.layers[0].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:03<00:00, 1331.75it/s]\n"
     ]
    }
   ],
   "source": [
    "imdb_val = ImdbReviews(dataroot=dataroot, split=\"val\", max_seq_len=imdb_train.max_seq_len, encoder=imdb_train.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = Haikunator().haikunate()\n",
    "print(run_id)\n",
    "tblog = path.expanduser(path.join(\"~/mldata/tblogs/imdb-reviews/\", run_id))\n",
    "tb = tf.keras.callbacks.TensorBoard(tblog, histogram_freq=0, update_freq=\"epoch\")\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "history = model.fit(imdb_train, validation_data=imdb_val, epochs=10, callbacks=[tb], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_test = ImdbReviews(dataroot=dataroot, split=\"test\", max_seq_len=imdb_train.max_seq_len, encoder=imdb_train.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(imdb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 250, 100)          9492400   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 9,509,457\n",
      "Trainable params: 9,509,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1, 100, input_length=imdb_train.max_seq_len))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 250, 100)          9492400   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 9,509,457\n",
      "Trainable params: 17,057\n",
      "Non-trainable params: 9,492,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[0].set_weights([embeddings])\n",
    "model.layers[0].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falling-bread-5890\n",
      "Train for 1250 steps, validate for 157 steps\n",
      "Epoch 1/10\n",
      "1250/1250 - 124s - loss: 0.5003 - acc: 0.7566 - val_loss: 0.4073 - val_acc: 0.8124\n",
      "Epoch 2/10\n",
      "1250/1250 - 112s - loss: 0.3718 - acc: 0.8362 - val_loss: 0.3232 - val_acc: 0.8616\n",
      "Epoch 3/10\n",
      "1250/1250 - 116s - loss: 0.3159 - acc: 0.8650 - val_loss: 0.3175 - val_acc: 0.8578\n",
      "Epoch 4/10\n",
      "1250/1250 - 118s - loss: 0.2878 - acc: 0.8792 - val_loss: 0.2873 - val_acc: 0.8794\n",
      "Epoch 5/10\n",
      "1250/1250 - 111s - loss: 0.2670 - acc: 0.8896 - val_loss: 0.2824 - val_acc: 0.8808\n",
      "Epoch 6/10\n",
      "1250/1250 - 111s - loss: 0.2509 - acc: 0.8978 - val_loss: 0.2669 - val_acc: 0.8898\n",
      "Epoch 7/10\n",
      "1250/1250 - 112s - loss: 0.2364 - acc: 0.9027 - val_loss: 0.2867 - val_acc: 0.8784\n",
      "Epoch 8/10\n",
      "1250/1250 - 113s - loss: 0.2237 - acc: 0.9099 - val_loss: 0.2620 - val_acc: 0.8966\n",
      "Epoch 9/10\n",
      "1250/1250 - 111s - loss: 0.2127 - acc: 0.9153 - val_loss: 0.2856 - val_acc: 0.8832\n",
      "Epoch 10/10\n",
      "1250/1250 - 111s - loss: 0.2024 - acc: 0.9190 - val_loss: 0.2758 - val_acc: 0.8928\n"
     ]
    }
   ],
   "source": [
    "run_id = Haikunator().haikunate()\n",
    "print(run_id)\n",
    "tblog = path.expanduser(path.join(\"~/mldata/tblogs/imdb-reviews/\", run_id))\n",
    "tb = tf.keras.callbacks.TensorBoard(tblog, histogram_freq=0, update_freq=\"epoch\")\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "history = model.fit(imdb_train, validation_data=imdb_val, epochs=10, callbacks=[tb], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
