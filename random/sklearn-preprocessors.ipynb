{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as skprep\n",
    "import torch as t\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the preprocessors come in two forms - a function or a class. A class is better because it can remember the parameters used for processing the training set and then reuse them on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization\n",
    "Converting a tensor of floats into zeros and ones based on a cutoff. Elements greater than the cutoff are replaced with ones, and elements less than are replaced with zeros. The built-in `Binarizer()` is useless. Much better to use the more common idiom of broadcast operators which is easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5191, 0.3862, 0.4847, 0.7220],\n",
       "        [0.2666, 0.9218, 0.2798, 0.9778],\n",
       "        [0.5845, 0.3524, 0.1679, 0.0645]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.rand((3, 4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  True],\n",
       "        [False,  True, False,  True],\n",
       "        [ True, False, False, False]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 1.],\n",
       "        [0., 1., 0., 1.],\n",
       "        [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x > 0.5).to(t.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skprep.Binarizer(threshold=0.5).transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "Standardization is when a column in the dataset is scaled to zero mean and unit variance. There are various types of scalers which operate on columns, Standardization is just one of the scalers. Other scalers scale the columns to some range, typically `[0, 1]`, scalers that take into account outliers, etc. See [sklearn documentation](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling) for other scalers. Below is a demo for `StandardScaler`.\n",
    "\n",
    "Contrast this with Normalization, which is when a row in the dataset is scaled to have unit norm. I haven't used it before so not showing the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets generate a dataset where the columns have different known means and variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "c1 = rng.normal(10, 30, 4).reshape(-1, 1)\n",
    "c2 = rng.normal(3, 1.5, 4).reshape(-1, 1)\n",
    "c3 = rng.normal(50, 3, 4).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 24.16918477,   2.37329517,  50.55234226],\n",
       "       [ 29.59843264,   4.95234935,  52.725133  ],\n",
       "       [-10.10438308,   2.73730604,  49.73805577],\n",
       "       [ -5.58256444,   3.02222418,  56.33356728]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.concatenate((c1, c2, c3), axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.52 17.542\n",
      "3.271 0.997\n",
      "52.337 2.553\n"
     ]
    }
   ],
   "source": [
    "c1_mean = np.round(np.mean(x[:, 0]), 3)\n",
    "c1_std = np.round(np.std(x[:, 0]), 3)\n",
    "\n",
    "c2_mean = np.round(np.mean(x[:, 1]), 3)\n",
    "c2_std = np.round(np.std(x[:, 1]), 3)\n",
    "\n",
    "c3_mean = np.round(np.mean(x[:, 2]), 3)\n",
    "c3_std = np.round(np.std(x[:, 2]), 3)\n",
    "\n",
    "print(c1_mean, c1_std)\n",
    "print(c2_mean, c2_std)\n",
    "print(c3_mean, c3_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets examine the mean and standard deviation for the rows as well for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.698 19.699\n",
      "29.092 19.506\n",
      "14.124 25.723\n"
     ]
    }
   ],
   "source": [
    "r1_mean = np.round(np.mean(x[0, :]), 3)\n",
    "r1_std = np.round(np.std(x[0, :]), 3)\n",
    "\n",
    "r2_mean = np.round(np.mean(x[1, :]), 3)\n",
    "r2_std = np.round(np.std(x[1, :]), 3)\n",
    "\n",
    "r3_mean = np.round(np.mean(x[2, :]), 3)\n",
    "r3_std = np.round(np.std(x[2, :]), 3)\n",
    "\n",
    "print(r1_mean, r1_std)\n",
    "print(r2_mean, r2_std)\n",
    "print(r3_mean, r3_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = skprep.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First calculate the params of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.52016747  3.27129369 52.33727458] [17.54241956  0.9974377   2.55258258]\n"
     ]
    }
   ],
   "source": [
    "std_scaler.fit(x)\n",
    "print(std_scaler.mean_, std_scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, if we are given any new row, typically from the test set, with 3 columns/elements (same thing for a row) we can transform it using these params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.15777383, 96.97719051, 18.67235395]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([100., 100., 100.]).reshape(1, -1)\n",
    "std_scaler.transform(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transform the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83506253, -0.90030536, -0.69926526],\n",
       "       [ 1.14455507,  1.68537409,  0.15194745],\n",
       "       [-1.11869121, -0.5353594 , -1.01827021],\n",
       "       [-0.86092639, -0.24970933,  1.56558802]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_x = std_scaler.transform(x)\n",
    "scaled_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify that the columns have zero mean and unit variance. The mean and variance of the rows will have changed but they will not neccessarily by zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 1.0\n",
      "-0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "c1_mean = np.round(np.mean(scaled_x[:, 0]), 3)\n",
    "c1_std = np.round(np.std(scaled_x[:, 0]), 3)\n",
    "\n",
    "c2_mean = np.round(np.mean(scaled_x[:, 1]), 3)\n",
    "c2_std = np.round(np.std(scaled_x[:, 1]), 3)\n",
    "\n",
    "c3_mean = np.round(np.mean(scaled_x[:, 2]), 3)\n",
    "c3_std = np.round(np.std(scaled_x[:, 2]), 3)\n",
    "\n",
    "print(c1_mean, c1_std)\n",
    "print(c2_mean, c2_std)\n",
    "print(c3_mean, c3_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.255 0.775\n",
      "0.994 0.635\n",
      "-0.891 0.255\n"
     ]
    }
   ],
   "source": [
    "r1_mean = np.round(np.mean(scaled_x[0, :]), 3)\n",
    "r1_std = np.round(np.std(scaled_x[0, :]), 3)\n",
    "\n",
    "r2_mean = np.round(np.mean(scaled_x[1, :]), 3)\n",
    "r2_std = np.round(np.std(scaled_x[1, :]), 3)\n",
    "\n",
    "r3_mean = np.round(np.mean(scaled_x[2, :]), 3)\n",
    "r3_std = np.round(np.std(scaled_x[2, :]), 3)\n",
    "\n",
    "print(r1_mean, r1_std)\n",
    "print(r2_mean, r2_std)\n",
    "print(r3_mean, r3_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "Given an array, usually the **target** column, with `k` categorical values, this preprocessor transforms it into a numeric column with values in `[0, k-1]` range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\"paris\", \"paris\", \"tokyo\", \"amsterdam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = skprep.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amsterdam', 'paris', 'tokyo'], dtype='<U9')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(cities)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, amsterdam will be encoded with 0, paris with 1, and tokyo with 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cannot specify the encoding by hand, i.e., if I want tokyo to be 0, there is no way that I know of to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Encoding\n",
    "Instead of an array, if I have a 2D dataset where each column is a different categorical feature, then I cannot use a `LabelEncoder`. I have to use an `OrdinalEncoder` instead. It does the same thing, i.e., replaces each column with integers between `[0, k-1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [['male', 'from US', 'uses Safari'], \n",
    "     ['female', 'from Europe', 'uses Firefox']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = skprep.OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['from Europe', 'from US'], dtype=object),\n",
       " array(['uses Firefox', 'uses Safari'], dtype=object)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit(x)\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This encoder cannot work on a single dimensional array. It will interpret each element as a column with a single unique value. We'd have to convert the array into a column vector first for this to work. This is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['amsterdam', 'paris', 'tokyo'], dtype='<U9')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(cities).reshape(-1, 1)\n",
    "enc = skprep.OrdinalEncoder()\n",
    "enc.fit(a)\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is why it is better to use `LabelEncoder` for such use cases. However, unlike `LabelEncoder` it is possible to specify the encoding manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['male', 'female'], dtype=object),\n",
       " array(['from US', 'from Europe'], dtype=object),\n",
       " array(['uses Safari', 'uses Firefox'], dtype=object)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = skprep.OrdinalEncoder(categories=[[\"male\", \"female\"], [\"from US\", \"from Europe\"], [\"uses Safari\", \"uses Firefox\"]])\n",
    "enc.fit(x)\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label One Hot Encoding\n",
    "Given a categorical array, the `LabelBinarizer` operator transforms it into a 2D matrix with each row being a one-hot encoded vector of the corresponding element in the input row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amsterdam', 'paris', 'tokyo'], dtype='<U9')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = skprep.LabelBinarizer()\n",
    "enc.fit(cities)\n",
    "enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset One Hot Encoding\n",
    "Similar to the categorical dataset above, we start with a 2D dataset with categorical columns. This encoder will blow up each column into a 2D sparse matrix with `k` columns. It returns a sparse tensor, which is why it needs to be converted by `toarray()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [['male', 'from US', 'uses Safari'], \n",
    "     ['female', 'from Europe', 'uses Firefox']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['from Europe', 'from US'], dtype=object),\n",
       " array(['uses Firefox', 'uses Safari'], dtype=object)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = skprep.OneHotEncoder(handle_unknown=\"ignore\")\n",
    "enc.fit(x)\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 0., 1.],\n",
       "       [1., 0., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(x).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `handle_unknown=\"ignore\"` is there so that if there is a row with some category value that was not in the training set (i.e., the dataset that the encoder was `fit`ted to, the one hot vector will have all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([\"female\", \"from US\", \"uses Chrome\"]).reshape(1, -1)\n",
    "enc.transform(a).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the output array, the last two elements, which are the one-hot encoded vector for browser use, are both zeros.\n",
    "\n",
    "As before, this will not work on a single dimensional array, it will only work with a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['amsterdam', 'paris', 'tokyo'], dtype='<U9')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(cities).reshape(-1, 1)\n",
    "enc = skprep.OneHotEncoder()\n",
    "enc.fit(a)\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(a).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
